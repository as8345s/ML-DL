{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8610038a-a040-4cb1-aa0d-117515c6e2ac",
   "metadata": {},
   "source": [
    "# Pytorch Deep-Learning | Multi-Node / Multi-GPU | Docker \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238778d6-e8bc-4861-9b5f-60d7616539bb",
   "metadata": {},
   "source": [
    "In diesem Notebook wird PyTorch DDP verwendet, um das Trainieren auf einem Dask-Cluster zu skalieren. \n",
    "\n",
    "Von Pytorch selber gibt es euch einige Anwendungsbeispiele für Deep-Learning.\n",
    "Saturncloud stellt uns Module bereit, einer dieser Module nennt sich Dask-PyTorch-DDP, was wir für das Trainieren mit Dask nutzen werden. <br>Ob Docker oder nicht, es muss ein Dask-Cluster erstellt werden, damit das mit Dask und PyTorch funktioniert. Die Worker sollten auf die GPU zugreifen können. \n",
    "\n",
    "\n",
    "Das verteilte Trainieren erfolgt so, dass wir unser Model als DDP-Model wrappen und mittels Dask auf die Worker verteilen. Das Verteilen findet im Hintergrund statt.\n",
    "\n",
    "<u>Wann sollte PyTorch DDP genutzt werden:</u><br>\n",
    "- Das Model passt auf eine GPU\n",
    "- Es gibt sehr viele Trainingsdaten.<br>\n",
    "DDP beschleunigt das Training, indem jeder erstellte Worker das gleiche Model mit unterschiedlichen Daten trainiert.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Dask und Dask.distributed sollten die gleiche Version haben. <br>\n",
    "Dask: https://www.dask.org && https://docs.dask.org/en/stable/ <br>\n",
    "PyTorch: https://pytorch.org  <br>\n",
    "PyTorch releases: https://github.com/pytorch/pytorch/releases <br>\n",
    "Dask-PyTorch-DDP Open Source Module von Saturncloud: https://github.com/saturncloud/dask-pytorch-ddp/tree/main <br>\n",
    "PyTorch DDP \"WHAT IS DISTRIBUTED DATA PARALLEL (DDP)\" https://pytorch.org/tutorials/beginner/ddp_series_theory.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75391cda-a122-4a8b-8202-8f154f65366e",
   "metadata": {},
   "source": [
    "# 1. PyTorch und Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657ec2c-dc98-4302-8114-0b002ee0d9fa",
   "metadata": {},
   "source": [
    "Um die Verwendung von PyTorch DDP und den erstellten Modulen zu veranschaulichen, wird das PyTorch Basic Tutorial für den Basisfall genutzt. <br>\n",
    "Daraufhin können  Anpassungen gemacht werden.\n",
    "\n",
    "\n",
    "Die Netzwerke und Trainingsloops ändern sich für das Verteilte Trainieren  mit DDP nicht groß. Die Trainingsfunktion wird von jedem Worker ausgeführt. Ein Worker entspricht einer GPU mit genau einem Prozess. \n",
    "\n",
    "<br>\n",
    "\n",
    "PyTorch Tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html<br>\n",
    "<p style=\"font-size:13px;\">Bilder aus dem Tutorial https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc812d1-b75e-4c18-a25d-4804d4a55b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div>\n",
    "    <p style=\"float: left;\"><img src=\"./pictures/pytorch_cnn_1.PNG\" border=\"1px;\" width=\"425px;\" hight=\"425px;\" ></p>\n",
    "    <p style=\"float: left;\"><img src=\"./pictures/pytorch_cnn_2.PNG\" border=\"1px;\" width=\"425px;\" hight=\"425px;\"></p>   <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbefdc75-27a1-47d1-b222-d38ee8e5bca1",
   "metadata": {},
   "source": [
    "Wir teilen das Training in 4 Bereiche auf. Hier nutzen wir MNSG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf73f5-d915-429d-b213-39afd50c000c",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<img src=\"./pictures/rapids_flynn.PNG\"  width=\"625px;\" hight=\"625px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d0c7d-d5ea-4bc6-b223-79d246da51dc",
   "metadata": {},
   "source": [
    "<u>PyTorch DDP kurz erklärt</u>\n",
    "\n",
    "DDP steht für Distributed Data Parallel. Nehmen wir an das wir 3 Nodes haben, mit je 1 GPU. PyTorch DDP startet 1 Prozess pro GPU, also haben wir am Ende 3 Prozesse. Ein Prozess nutzt ein CPU-Kern. Das Data Parallel entsteht dadurch, dass die Trainingsdaten parallel in die Netze gefüttert werden. Jeder Worker kann die lokalen Daten nutzen, in der Trainingsfunktion die jeder Worker ausführt, kann definiert werden wie Daten geladen werden.\n",
    "\n",
    "Wenn nur der Host die Daten hat, müssen diese mit dem Cluster geteilt werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d51d7-43a9-4720-8411-3d7424981179",
   "metadata": {},
   "source": [
    "Die Abbildung unten zeigt 3 Nodes mit jeweils 1 GPU. Jede GPU hat eine Kopie des Models. Zum Trainieren werden die lokalen Daten geladen. Wie Daten geladen werden, ist den Benutzern überlassen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d5953-f288-4ba6-a85c-66c5857c37e3",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./pictures/5_DDP.PNG\"  width=\"925px;\" hight=\"725px;\">\n",
    "<!--</center>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1310c5f-f590-41c5-8df1-56247ded8da6",
   "metadata": {},
   "source": [
    "Da wir die Trainingsdaten aufteilen, bekommt jedes Model einen anderen Input. Wenn das Netz auf eine GPU gut passt, wird das Model einfach auf die GPUs kopiert. Jeder Worker hat dann das gleiche Model zu Beginn, sowie Optimierer, usw. als wäre man nur auf einer lokalen Maschine.\n",
    "\n",
    "Passt ein Model nicht auf eine GPU, so muss das Model aufgeteilt werden => Model Parallel <br>\n",
    "Das ist in einem anderem Notebook beschrieben.\n",
    "\n",
    "Die Synchronisation erfolgt mittels eines bucketed Ring All-Reduce Algorithmus. Die Layers des Models werden in sogenannten Buckets organisiert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700a3cf-a3c9-4559-8850-d97d5f8d25a0",
   "metadata": {},
   "source": [
    "Bild aus dem <a href=\"https://www.youtube.com/watch?v=3XUG7cjte2U\">Erklärvideo:</a> <br>                         \n",
    "<img src=\"./pictures/3_DDP.png\" width=\"425px;\" hight=\"550px;\">\n",
    "<img src=\"./pictures/4_DDP.PNG\" width=\"425px;\" hight=\"550px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0c567-8f6d-4b00-b3a7-0999a2293756",
   "metadata": {},
   "source": [
    "PyTorch kümmert sich dann um den Rest.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Ring All-Reduce: https://tech.preferred.jp/en/blog/technologies-behind-distributed-deep-learning-allreduce/<br>\n",
    "PyTorch DDP \"GETTING STARTED WITH DISTRIBUTED DATA PARALLEL\": https://pytorch.org/tutorials/intermediate/ddp_tutorial.html <br>\n",
    "PyTorch DDP Erklärvideo (von PyTorch YouTube): https://www.youtube.com/watch?v=Cvdhwx-OBBo&list=PL_lsbAsL_o2CSuhUhJIiW0IkdT5C2wGWj&index=2  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1453ac-6b17-4cc7-88e3-3121330eefea",
   "metadata": {},
   "source": [
    "# 2. Aufbau und Möglichkeiten "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820363ec-228b-44a9-86cd-5f74619b58c4",
   "metadata": {},
   "source": [
    "Wir importieren Dateien, die Klassen und Funktion erhalten, um die Benutzung zu vereinfachen.\n",
    "\n",
    "In den Modulen selber können Einstellungen vorgenommen werden. Wenn PYTORCH_MODULE_LOG auf False gesetzt wird, werden keine Informationen ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4095c6-9676-468c-8542-8cc98d8808a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools 1.0 | Setze Umgebungsvariablen\n",
      "PYTORCH_DIST_BACKEND: nccl\n",
      "PYTORCH_DIST_DDP_PORT: 23456\n",
      "NCCL_SOCKET_NTHREADS: 4\n",
      "NCCL_NSOCKS_PERTHREAD: 2\n",
      "PYTORCH_MODULE_LOG: True\n",
      "\n",
      "RPC Config:\n",
      "GLOO_SOCKET_IFNAME: eno1, NCCL_SOCKET_IFNAME: eno1\n",
      "TP_SOCKET_IFNAME: eno1    , START_ON_RANK: 0\n",
      "PyTorch Dispatcher-/Resulthandler 1.0\n"
     ]
    }
   ],
   "source": [
    "## Tools um die Nutzung zu vereinfache\n",
    "# - Das Modul selber imortiert auch pytorch_dispatcher_resulthandler\n",
    "import pytorch_tools as pytorch_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d5637e-e2bd-4add-a645-4a608afbac00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code für PyTorch DDP\n",
    "import pytorch_dispatcher_resulthandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2c3454-5b58-4e0f-8cff-531cff056267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client-IP: 127.0.0.1:8786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-065c0bd1-84a7-11ee-b135-a4bb6d4fbfd8</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"http://127.0.0.1:8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-cbc9e132-7c92-47ce-ad33-0a1794533d5a</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://149.201.182.203:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 2\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://149.201.182.203:8787/status\" target=\"_blank\">http://149.201.182.203:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 2\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> 1 hour ago\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 125.06 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: tcp://149.201.182.188:45851</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://149.201.182.188:45851\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://149.201.182.188:42299/status\" target=\"_blank\">http://149.201.182.188:42299/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 62.53 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://149.201.182.188:35995\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-6o7jx3gc\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Quadro RTX 5000\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 8.0%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 3.14 GiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 18.11 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 1.66 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: tcp://149.201.182.203:42399</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://149.201.182.203:42399\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://149.201.182.203:35851/status\" target=\"_blank\">http://149.201.182.203:35851/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 62.53 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://149.201.182.203:36345\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-w5jys_e0\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Quadro RTX 5000\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 8.0%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 3.14 GiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 64.96 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 80.39 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://149.201.182.203:8786' processes=2 threads=2, memory=125.06 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Client \n",
    "client = pytorch_tools.create_dask_client()  # Gebe IP an. Standart:  127.0.0.1:8786 (Scheduler ist da wo auch Jupyter läuft)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba7169-c08a-481b-b45c-782c05cd7388",
   "metadata": {},
   "source": [
    "Das Modul enhält Klassen, Funktionen und setzt Umbegungsvariablen, die auch andere Worker sehen müssen. Damit das kappt, muss das Modul im Cluster hochgeladen werden. <br> \n",
    "\n",
    "Wenn die Module verändert werden, müssen diese erneut hochgeladen werden. Beim Erstellen des Clients mit \"pytorch_tools.create_dask_client()\" wird die Funktion \"scatter_files()\" aufgerufen, das diese Module hochlädt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66d8ca2-5fb7-44e3-a076-49aaf6fc3d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## So werden die Module pytorch_tools.py und pytorch_dispatcher_resulthandler.py mit dem Cluster geteilt. \n",
    "#  *Bei Änderungen muss der Kernel in Jupyter neugestartet werden. \n",
    "pytorch_tools.scatter_files(client) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f74b14-d341-4db6-8a3b-4a81d3bc470e",
   "metadata": {},
   "source": [
    "Wenn wir eigene Module erstellen, können wir diese auch mit dem Cluster teilen. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d659b04-d25a-4f0f-833b-21c35ebdb0fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lade Datei hoch. Gibt Status aus... \n",
    "#  - ggf. müssen die Verzeichnisse angepasst werden.\n",
    "client.upload_file('myfile.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e75e4a-b24e-49d7-84b5-db9f8d26ebae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tcp://149.201.182.188:44333', 'tcp://149.201.182.205:45123'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zeige Schlüssel. Die Ports ändern sich. \n",
    "client.has_what().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "487df301-8356-4fe6-92d7-6c05ad47fe82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tcp://149.201.182.188:46327', 'tcp://149.201.182.203:45273', 'tcp://149.201.182.205:32919'])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starte alle Worker neu\n",
    "client.restart_workers( client.has_what().keys() )\n",
    "client.has_what().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d19ea200-d091-45f5-a0af-9f945f2d9530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Startet client neu.\n",
    "#client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b896152-b89c-4c86-9ab4-c1dccf88e9c8",
   "metadata": {},
   "source": [
    "Das Setup mit Docker kann so aussehen. Es gibt eine Node die Scheduler ist. Diese Node kann auch einen Worker haben. \n",
    "\n",
    "Wenn der Scheduler auch worker sein soll, muss eine zweite Konsole geöffnet werden, um den Worker zu starten. Wer am Ende Scheduler ist, ist egal, alle Knote sind gleichberechtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12cc4e-e8fe-4480-bdb5-b4f047cd2ba1",
   "metadata": {},
   "source": [
    "Beispiel Setup (auf Node1 läuft auch Jupyter).: <br>\n",
    "<img src=\"pictures/cluster_setup.PNG\" width=\"925px;\" hight=\"850px;\"><br>\n",
    "Docker logo:<br>\n",
    "https://www.docker.com/company/newsroom/media-resources/![cluster_setup.png](attachment:9a543a66-02b7-4661-a8f9-a9be164d0575.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f8fcb-8e54-451c-9aa7-d5028b8dadbe",
   "metadata": {},
   "source": [
    "Das untere Bild zeigt, wie die Aufteilung von Client, Worker und Scheduler sein könnten. Nachrichten und das Model selber werden an den Client geschickt, da von dort aus die Traningsfunktion mit Dask an die Worker submitet wird. Der Resulthandler der sich auf dem Client befindet, sammelt die Nachrichten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab9082-6b9a-4770-9daf-64bdd95e74de",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/cluster_aufbau.PNG\" width=\"725px;\" hight=\"850px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa61035-604b-46d8-a14b-18d771e422f4",
   "metadata": {},
   "source": [
    "Als Erstes kommen die Importe, was fehlt, kann dazugenommen werden. Alle Knoten (falls Cluster) sollten dieselben Pakete installiert haben, möglichst mit derselben Version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a1b72c-4f9b-434d-b5ca-42dcab31f399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports die wir benötigen\n",
    "###########################################################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "import torchvision\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "from distributed.pubsub import Pub, Sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688cb67-9b55-46dc-9c87-acdecdfd6fb6",
   "metadata": {},
   "source": [
    "Was passiert im Hintergrund?<br>\n",
    "Es wird pro Worker eine Funktion submitet. Diese Funktion ist unsere Trainingsfunktion. Jeder Worker führt das Training aus und nutzt die eigenen Daten. Wenn Daten lokal geladen werden, werden keine Daten über das Netzwerk geteilt. Wie Daten geladen werden, ist ganz dem Benutzer überlassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac92475-96d4-42d6-bf6e-99f1dc9709ad",
   "metadata": {},
   "source": [
    "<u>Hinweis:</u><br>\n",
    "Bei `run()` sollte ein freier Port angegeben werden, eingestellt ist <u>23456</u>. Siehe pytorch_dispatcher_resulthandler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78e288-b456-4e08-bdc5-16ad0ca3d539",
   "metadata": {},
   "source": [
    "Vereinfacht würde das so aussehen:\n",
    "\n",
    "<img  src=\"./pictures/dispatcher_flow.PNG\" width=\"1100px;\" hight=\"900px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d4c2a-5452-4a67-a77b-9786ed212ea0",
   "metadata": {},
   "source": [
    "Jeder Worker kann Nachrichten ausgeben. Es wird ein Channel erstellen, mit einem Subscriber und mehreren Publishern (die Worker). Der Host (z.B. Jupyter) bekommt die Nachrichten. Sobald was auf den Channel gelegt wird, liest der Subscriber diese Daten. "
   ]
  },
  {
   "attachments": {
    "3539fc8c-2fa8-4c6a-834c-f7721640d15e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "fe9a71c6-7dd2-48f5-bcc5-07350bd63506",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "<p style=\"float: left;\"><img src=\"./pictures/pubsub2.PNG\" width=\"625px;\" hight=\"750px;\" ><![pubsub2.png](attachment:3539fc8c-2fa8-4c6a-834c-f7721640d15e.png)/p>\n",
    "<p style=\"float: left;\"><img src=\"./pictures/pubsub3.PNG\" width=\"625px;\" hight=\"750px;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55b60f-d313-4e9b-88b7-2ae7e3638b0e",
   "metadata": {},
   "source": [
    "## 2.2 Netzwerke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814a3da-fc0f-4bdb-9537-4af11d5096ff",
   "metadata": {},
   "source": [
    "Es gibt verschiedene Netzwerke und Wege diese zu erstellen. Bei DDP wird das Netzwerke auf allen Knoten kopiert und dann mit den Trainingsdaten versorgt. Das klappt gut, wenn das Netzwerk auf eine GPU passt. \n",
    "\n",
    "Ist das Netzwerk zu groß für eine GPU, können die Layers auf die GPUs aufgeteilt werden => Model Parallel. \n",
    "Zu Model Parallel gibt es ein separates Notebook.\n",
    "\n",
    "\n",
    "Bei der Struktur der Netzwerke muss hauptsächlich darauf geachtet werden, dass bestimmte Teile explizit auf die GPU geschoben werden.\n",
    "\n",
    "So könnten Netzwerke aussehen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2b6624-c3b0-4816-9f42-2ccfb27fe4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################              \n",
    "###  Beispiel Netzwerke die man bei DDP nutzen könnte.\n",
    "#############################\n",
    "\n",
    "# CNN | PyTorch Basic Tutorial | https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# RNN | https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/#3-building-a-recurrent-neural-network-with-pytorch-gpu\n",
    "class Model_2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(Model_2, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)                                 # Hier:  to(device)\n",
    "\n",
    "        # One time step\n",
    "        # We need to detach the hidden state to prevent exploding/vanishing gradients\n",
    "        # This is part of truncated backpropagation through time (BPTT)\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100 \n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "    \n",
    "\n",
    "# LSTM | https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/ \n",
    "# - Mit CSV Datei einlesen\n",
    "class Model_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "# LSTM | https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/#model-c-3-hidden-layer\n",
    "class Model_4(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(Model_4, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros                                       \n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()                # Hier: device=x.device  oder .to(device), siehe RNN\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device=x.device).requires_grad_()                # Hier: device=x.device  oder .to(device), siehe RNN\n",
    "\n",
    "        # One time step\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "    \n",
    "# Autencoder | https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
    "class Model_5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "         \n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 784 ==> 9\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9)\n",
    "        )\n",
    "         \n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        # 9 ==> 784\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 28 * 28),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bb8a1-1629-4c0d-a329-09218e4be549",
   "metadata": {},
   "source": [
    "Diese Netzwerke sind Beispiele, wie sowas aussehen könnte. Bei den RNN und LSTM Modellen ist zu beachten, dass man bei forward() h0, c0, ..., auf die GPU packt mittels `.to(device)` oder mit `device=x.device`. Wenn man es nicht macht, kommt ein Fehler, dass Teile auf der GPU und CPU sind. Falls so ein Fehler auftaucht, wird normalerweise gesagt, wo und woran es liegt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd2c5a-4a2a-4891-91d6-1237fbe08703",
   "metadata": {},
   "source": [
    "## 2.3 Trainingsroutine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf117ec-8bfc-4813-ba2d-89a05e8928c6",
   "metadata": {},
   "source": [
    "\n",
    "Wir betrachten wir den Fall, dass wir ein Docker Cluster Setup haben. PyTorch DDP kann mit 1 Worker gut umgehen, will man mehrere, startet man mehrer Worker. Man selber muss sich keine Gedanken um das Skalieren machen.\n",
    "\n",
    "\n",
    "Die <u>Batchgröße</u> kann die Geschwindigkeit und Qualität des Trainings beeinflussen. \n",
    "\n",
    "Im Folgendem könne wir auch ein <u>DDP Hook nutzen</u>. Der Hook hier heißt PowerSGD Hook. Es komprimiert die Kommunikation und ist geeignet wenn die Netzwerkkommunikation ein Bottleneck ist, besonders wenn das Model groß ist. Eine umfassende Beschreibung find man in dem Paper. Bei kleineren Modellen kann es zu keinem Unterschied kommen, man kann es trotzdem ausprobieren.\n",
    "\n",
    "Der PowerSGD Hook hat 2 Wichtige Parameter:<br>\n",
    "`matrix_approximation_rank:int` Kompressionsrate, ein hoher Wert kann die Berechnungskosten der Kompression steigern. Starte bei 1 und erhöhe immer um 2.  <br>\n",
    "`start_powerSGD_iter:int` Warte bis zum Schritt n, dann führe ein All Reduce der vorherigen Schritte durch. Vorgeschlagen wird ein Wert <br>\n",
    "der Größe 10% der gesamten Trainingsschritte. \n",
    "\n",
    "Der Zweck des Hooks ist es, die Kommunikation beim verteilten Trainieren zu verbessern. <br>\n",
    "Es gibt noch weitere Hooks: fp16_compress_hook(), bf16_compress_hook() und batched_powerSGD_hook(). Momentan wird hier nur der PowerSGD und fp16_compress_hook Hook angeboten. <br>\n",
    "Die Hooks für bf16 brauchen eine NCCL Version > 2.9.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f98e6f-b50f-4a29-9992-86938536ec5c",
   "metadata": {},
   "source": [
    "<u>Was wir zusätzlich nutzen können:</u> <br>\n",
    "Distributed Optimizer, die die Kommunikation und Optimierung beeinflussen. Siehe (https://pytorch.org/docs/main/distributed.optim.html#torch.distributed.optim.DistributedOptimizer) <br>\n",
    "DDP Hooks, um die Kommunikation mit DDP zu beeinflussen. Siehe (https://pytorch.org/docs/stable/ddp_comm_hooks.html)<br>\n",
    "BF/FP16 Format statt float32, kann die Berechnungskosten senken. Zur Anwendung siehe hier (https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html#default-precision)\n",
    "\n",
    "Alle drei haben <u>Einfluss</u> auf die Trainingszeit und die Genauigkeit des Models. Der Optimierer und Hooks sind im Modul enthalten und können einfach eingesetzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381d6af-c16d-4229-9d6b-9bcbd9c7d293",
   "metadata": {},
   "source": [
    "Anwendung von:<br>\n",
    "Distributed Optimizer: PostLocalSGDOpt mit `model, optimizer = pytorch_tools.register_distOpt_PostLocalSGDOpt(model, device_id, optimizer, period=4, warm_up:int=100)`.  <br>\n",
    "Hook PowerSGD: `model = pytorch_tools.register_DDP_PowerSGD_hook(model, device_id, matrix_approximation_rank:int=12, start_powerSGD_iter:int=2)`. <br>\n",
    "Hook PowerSGD fp16: `model = pytorch_tools.register_fp16_compress_wrapper_SgdPower_hook(model, device_id, matrix_approximation_rank:int=12, start_powerSGD_iter:int=2):`\n",
    "\n",
    "\n",
    "Der Optimierer PostLocalSGDOpt läuft auf jedem Worker. <br>\n",
    "`period` gibt an, dass alle 4 Schritte Global gemittelt wird. `warm_up` gibt an, dass die ersten 100 Schritte die Gradienten lokal gemittelt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36291dcc-4408-4814-9e31-19df4b8fb362",
   "metadata": {},
   "source": [
    "Das untere Beispiel zeigt, wie ein Training aussehen könnte. Wir nutzen dafür das Model aus dem Basic PyTorch Tutorial und das Cifar10 Dataset, was jeder Worker aus dem Internet lädt.\n",
    "\n",
    "Wenn dieser Ablauf funktioniert, sollte es keine Probleme mit dem verteilten Trainieren geben. Man kann so den <u>Aufbau testen</u>, sowie Dask und den Cluster.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "DDP Hook:<br>\n",
    "https://pytorch.org/docs/stable/ddp_comm_hooks.html <br>\n",
    "- Science Paper: https://arxiv.org/pdf/1905.13727.pdf\n",
    "- Accelerating PyTorch DDP by 10X With PowerSGD (Von PyTorch): https://medium.com/pytorch/accelerating-pytorch-ddp-by-10x-with-powersgd-585aef12881d\n",
    "- Verfügbare PyTorch Hooks: https://medium.com/analytics-vidhya/pytorch-hooks-5909c7636fb\n",
    "\n",
    "Distributed Optimizer:<br>\n",
    "- post-local SGD https://pytorch.org/docs/main/distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer  Paper: https://arxiv.org/abs/1808.07217"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f79623-fa03-47d5-89cf-af238a7604f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<u>Hinweis:</u><br>\n",
    "Wenn es hängt oder bei Problemen: Worker/Notebook/Cluster, ... neustarten.<br>\n",
    "Das kann manchmal helfen. Das Problem kann auftauchen, wenn Exceptions vorkommen. \n",
    "\n",
    "Die Registrierung eines Hooks mit \"register_comm_hook\" kann nur einmal stattfinden (passiert im Hintergrund). Das bedeutet, dass das entweder PowerSGD oder ein Distributed Optimizer genutzt werden kann, beides geht nicht. \n",
    "\n",
    "Wenn man beides nutzt, wird eine Exception geworfen: \"Exception: \"RuntimeError('register_comm_hook or register_builtin_comm_hook can only be called once.')\"\"<br>\n",
    "\n",
    "\n",
    "<u>Hinweis zum Dataloader:</u><br>\n",
    "Um die Parameter num_workers und prefetch_factor zu nutzen, muss unter Dask eingestellt werden, dass die Worker nicht als Daemon Prozesse starten. Diese Parameter können die Trainingszeit verkürzen. <br>\n",
    "`num_workers:int` Erstelle n-Prozesse zum laden der Daten. <br>\n",
    "`prefetch_factor:int` Lade n-Batches vor. \n",
    "\n",
    "Damit das funktioniert, muss <u>vor</u> dem start der Worker eine Umgebungsvariable gesetzt werden. Bei jedem Worker muss es gesetzt sein. <br>\n",
    "Setze: `DASK_DISTRIBUTED__WORKER__DAEMON=False`. Der Standartwert ist `True`.\n",
    "\n",
    "\n",
    "Eine Abfrage kann so gemacht werden:<br>\n",
    "`dask.config.get(\"distributed.worker.daemon\")`. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Setzen und abfragen von Einstellungen in Dask: https://docs.dask.org/en/latest/configuration.html#conversion-utility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de39759-d177-41e5-907c-689fe873647b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Trainingsfunktion die jeder Worker ausführt. \n",
    "\n",
    "def train():\n",
    "    \n",
    "    pub_stats  = Pub(\"my_channel\")                          # Channel für Nachrichten              \n",
    "    worker_rank = int(dist.get_rank())                      # Globaler Rank\n",
    "    worker_ip = os.getenv('WORKER_HOST')                    # Worker IP\n",
    "    device_id = worker_rank % torch.cuda.device_count()\n",
    "    \n",
    "    device = torch.device(\"cuda\")  # 'cuda': Nutze alle GPUs | 0: nutze GPU 0 | 'cpu': Nutze CPU, Backend auf gloo stellen | \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \"\"\"Edits: \n",
    "    num_epochs: Epochen\n",
    "    batch_size: Batchgröße \n",
    "      - Die Auswahl von batch_size kann die Trainingszeit und Genauigkeit beeinflussen.\n",
    "    transform: Transformiere Bilddaten\n",
    "    trainset: Erstellt ein PyTorch Dataset. \n",
    "      - Wie man eigene Datasets erstellt findet, man weiter unten. \n",
    "    sampler: Nutze Sampler, wenn alle Daten auf allen Knoten gleich sind, und sich nicht unterscheiden.\n",
    "      - Hier hat jeder das Cifar10 Dataset, der Sampler sorgt für die gleichmäßige Aufteilung. \n",
    "    \"\"\"\n",
    "    num_epochs = 5     # Change\n",
    "    batch_size = 16    # Change  \n",
    "\n",
    "    transform = transforms.Compose( [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform) # Das Dataset liegt bei jedem Worker in ./data\n",
    "    # PyTorch DistributedSampler:\n",
    "    # - Wenn alle Daten gleich sind, sorgt der DistributedSampler für die Aufteilung dieser Daten.\n",
    "    sampler = DistributedSampler(trainset)\n",
    "    # Beim Dataloader kann num_workers und prefetch_factor übergeben werden. In Dask bevor die Worker starten: export DASK_DISTRIBUTED__WORKER__DAEMON=False\n",
    "    loader = DataLoader(trainset, batch_size=batch_size, sampler=sampler, num_workers=2, prefetch_factor=4, pin_memory=True ) #num_workers=2, prefetch_factor=1, pin_memory=True\n",
    "    \n",
    "    \n",
    "    # the model has to both be passed to the GPU device, then has to be wrapped in DDP so it can communicate with the other workers\n",
    "    model = Model().to(device) \n",
    "    # Model direkt in DDP umwandeln.  \n",
    "    model = DDP(model,  device_ids=[device_id]) \n",
    "    \n",
    "    ##  - Nutze Hook: - ##\n",
    "    # - Paramater: model, device_id, matrix_approximation_rank:int=12, start_powerSGD_iter:int=2\n",
    "    #model = pytorch_tools.register_DDP_PowerSGD_hook(model, device_id)   # SGD Hook, Model wird dort auch in DDP umgewandelt.  \n",
    "\n",
    "\n",
    "    # Edits:\n",
    "    # - optimizer und criterion laufen Lokal auf jedem Worker. \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    ## - Kann einen verteilten Optimierer nutzen. Dann aber keinen anderen Hook. - ##\n",
    "    # - register_distOpt_PostLocalSGDOpt(model,  device_id, local_optim, period:int=4, warm_up:int=100)\n",
    "    #model, optimizer = pytorch_tools.register_distOpt_PostLocalSGDOpt(model, device_id, optimizer)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # this ensures the data is reshuffled each epoch, if using sampler. \n",
    "        sampler.set_epoch(epoch)\n",
    "         \n",
    "        correct = 0\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            # Verschiebe X, y auf GPU\n",
    "            outputs = model(batch_x.to(device))                     # Oder vorher:  batch_x = batch_x.to(device)    batch_y = batch_y.to(device)  \n",
    "            loss = criterion(outputs, batch_y.to(device))\n",
    "            \n",
    "            # PyTorch DDP Gradient AllReduce\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()   \n",
    "            \n",
    "            \"\"\" Schreibe Nachricht   \n",
    "            if worker_rank == 0:  # Worker x \n",
    "                msg = \"...\"  # loss.item(), ...\n",
    "                pub_stats.put({\"msg\": msg})  # Wird in Jupyter angezeigt, Dict wird ausgegeben.  \n",
    "            \"\"\"\n",
    "\n",
    "           #  Während des Trainierens können verschiedene Werte berechnet werden, wie die accuracy.\n",
    "        \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if torch.cuda.is_available():\n",
    "                correct += (predicted.cpu() == batch_y.cpu()).sum()\n",
    "            else:\n",
    "                correct += (predicted == batch_y).sum()\n",
    "        accuracy = 100 * correct / len(trainset)\n",
    "\n",
    "        \n",
    "        # Worker 0 soll Model senden und gibt Nachricht aus.\n",
    "        if worker_rank == 0: # jede Epoche\n",
    "\n",
    "            msg = f\"loss: {round(loss.item(), 4)} acc: {accuracy}  epoche: ({epoch+1}/{num_epochs})\"\n",
    "            pub_stats.put({\"msg\": msg})\n",
    "            \n",
    "            ## Model als Dict, Pfad, **kwargs wie epoch=epoch\n",
    "            # - pytorch_tools.ddp_save_model_dict(channel, model_dict, path, **kwargs)\n",
    "            pytorch_tools.ddp_save_model_dict(pub_stats, model.state_dict(), \"./DDPmodel\", epoch=epoch)\n",
    "            # ** Oder auch: model.module.state_dict() \n",
    "            #    - Dann muss beim Laden das Model nicht als \"torch.nn.DataParallel( Model() )\" gewrapped werden.  \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7665c99-b059-4801-87f6-1d785912d8e9",
   "metadata": {},
   "source": [
    "Das Model wird als Dict gespeichert. Beim Speichern können noch weitere Daten mitgegeben werden, die beim späteren Laden dann verfügbar sind. <br>\n",
    "Das Dict mappt die zugehörigen Layers des Models zu den Parametern. Nicht das ganze Model wird gespeichet. \n",
    "\n",
    "Mit `pytorch_tools.ddp_save_model_dict(pub_stats, model.state_dict(), \"./DDPmodel\")` wird das Model gespeichert und enthält die Endung `.pt`. <br>\n",
    "Es werden nur die Trainierten Parameter gespeichert. \n",
    "\n",
    "Werden weitere Parameter wie Epoche übergeben, wird ein Checkpoint mit der Endung `.ckpt` erstellt.  So könnte das Speichern aussehen: <br>\n",
    "`pytorch_tools.ddp_save_model_dict(pub_stats, model.state_dict(), \"./DDPmodel\", epoch=epoch, optimizer_state_dict=optimizer.state_dict() )`.\n",
    "\n",
    "Mit diesen oberen zwei Methoden kann das Model als Dict über das Netzwerk gesendet werden, damit der Client die Resultate bekommt. <br>\n",
    "Anders sieht es aus, wenn das ganze Model verschickt werden soll, da gibt es bei der Serialisierung Probleme. <br>\n",
    "Momentan kann das Model nur als Dict gespeichert werden. \n",
    "\n",
    "\n",
    "<br>\n",
    "Mehr Informationen über das Speichern und Laden in PyTorch: <br> \n",
    "\n",
    "What is a state_dict?: https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict  <br>\n",
    "Saving & Loading Model for Inference (Endung .pt oder .pth): https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference <br>\n",
    "Export/Load Model in TorchScript Format:  https://pytorch.org/tutorials/beginner/saving_loading_models.html#export-load-model-in-torchscript-format <br>\n",
    "Saving & Loading a General Checkpoint for Inference and/or Resuming Training (Endung ckpt.): https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa1e2a3-bb10-419e-a0f7-295b4af2db8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker count: 2\n",
      "Start training\n",
      "\n",
      "loss: 2.0959 acc: 9.043999671936035  epoche: (1/5)\n",
      "loss: 1.5769 acc: 17.36199951171875  epoche: (2/5)\n",
      "loss: 1.343 acc: 21.17799949645996  epoche: (3/5)\n",
      "loss: 1.2019 acc: 23.350000381469727  epoche: (4/5)\n",
      "loss: 1.5007 acc: 25.110000610351562  epoche: (5/5)\n",
      "Time elapsed: 56.15068078041077\n",
      "16.11.2023  17:40:19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Am Ende wird die Systemzeit ausgegeben. Die Stunden können abweichen. Mit date_time_hour_offset kann es angepasst werden. Rechne zur Uhrzeit +/- n-Stunden.\n",
    "# - pytorch_tools.run(train, client, date_time_hour_offset:int=0 )  Zeitformat:  Tag-Monat-Jahr  Stunde-Minute-Sekunde\n",
    "pytorch_tools.run(train, client) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd72be-a6d6-4216-b297-128c65b28dba",
   "metadata": {},
   "source": [
    "Die Trainingsfunktion kann auch Parameter annehmen, um pro Worker bestimmte Entscheidungen zu treffen, wie das Laden verschiedener Daten aus verschiedenen Verzeichnissen.\n",
    "\n",
    "Das Beispiel unten wird das Vorgehen erläutern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d7191-29e1-4293-a43c-ef65b9ec1298",
   "metadata": {},
   "source": [
    "Diese Methoden zeigt, wie das Modul die Informationen erfasst, die dann für die Verteilung genutzt werden.<br>\n",
    "Jeder Worker führt auch ein Print aus indem IP, Rang und lokaler Rang ausgegeben werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40459287-554a-4c4f-ba4f-8516e1efe8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'worker': 'tcp://149.201.182.188:45851',\n",
       "  'local_rank': 0,\n",
       "  'global_rank': 0,\n",
       "  'host': '149.201.182.188'},\n",
       " {'worker': 'tcp://149.201.182.203:42399',\n",
       "  'local_rank': 0,\n",
       "  'global_rank': 1,\n",
       "  'host': '149.201.182.203'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aufteilung der Worker\n",
    "pytorch_tools.listDaskWorker(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63074bd-7d8c-42b3-8b27-34d75098c901",
   "metadata": {},
   "source": [
    "Jeder Worker kann durch einen Rank erkannt werden. Durch Abfragen in der Trainingsfunktion von IP und anderen Informationen z.B. mittels Python, kann jeder <br>\n",
    "Worker bestimmte Aufgaben erledigen. Als Beispiel soll jeder Worker mit seiner IP eine Liste auswählen. Bei mehreren Workern mit gleicher IP müssen mehr <br>\n",
    "Erkenungsmerkmale wie Port oder Rang genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df5b5cc-fc98-4062-802b-ff1eb48f474f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Unterteile Daten als Dict oder anders.\n",
    "# Jeder Worker mit IP soll eine bestimmte Liste bekommen. Jeder Worker bekommt diese Parameter. \n",
    "shared_info = {'worker_data': { '149.201.182.203': [1,2,3,4], '149.201.182.188': [5,6,7,8] } }                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a994b8a-f589-4274-9564-a4fdff47e2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameter task\n",
    "def train_test(task):\n",
    "    pub_stats   = Pub(\"my_channel\")                \n",
    "    worker_rank = int(dist.get_rank())                  # Globaler Rank\n",
    "    worker_ip   = os.getenv('WORKER_HOST')              # Worker IP\n",
    "    # Mit Python können auch andere Merkmale wie Hostname ermittelt werden. \n",
    "    \n",
    "    time.sleep(2)\n",
    "    data = task['worker_data'][worker_ip]\n",
    "    msg = f\"I'm worker {worker_ip} and my list is {data}\"\n",
    "   \n",
    "    pub_stats.put({\"msg\": msg}) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba0150c-4094-400a-af1a-01404ef5362e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker count: 2\n",
      "Start training\n",
      "\n",
      "I'm worker 149.201.182.203 and my list is [1, 2, 3, 4]\n",
      "I'm worker 149.201.182.188 and my list is [5, 6, 7, 8]\n",
      "Time elapsed: 5.042824745178223\n",
      "16.11.2023  17:40:45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pytorch_tools.run(train_test, client, task=shared_info) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5458fb75-4dc7-4def-ba68-a4db426ba681",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Auch so möglich: \n",
    "\n",
    "def train_test(a:int, b:int=100):\n",
    "    # ...\n",
    "    msg = f\"I'm worker {worker_ip} | {a+b}\"\n",
    "    # ...\n",
    "pytorch_tools.run(train_test, client, a=10, b=22) \n",
    "\n",
    ">> I'm worker ... | 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19c68b-0e28-4512-8e6b-7866f93f314c",
   "metadata": {},
   "source": [
    "### 2.3.2 Evaluieren in der Trainingsloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ed25e-6e9a-4938-af24-8c2dcbcf51e0",
   "metadata": {},
   "source": [
    "Bei dem Trainieren kann man neben dem normalen Vorgehen auch das Model gleichzeitig evaluieren, dazu muss man auch einiges beachten. Eines der wichtigen Dinge ist, dass bestimmte Teile auf der GPU und andere auf der CPU sein müssen, damit das Evaluieren gut geht, sonst tauchen Fehler auf.\n",
    "\n",
    "Das folgende Beispiele zeigt eine Trainingsschleife, wo auch die Genauigkeit getestet wird. Aufkommende Fehlern weisen auf die Bereiche hin, es kann vorkommen das manche Fehlermeldungen nicht sehr aussagekräftig sind, meist findet man auf GitHub und andere Webseiten Lösungen dazu."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd696051-af18-4289-9bfe-3119846f4f78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RNN |  dnn_RNN Notebook | https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/#3-building-a-recurrent-neural-network-with-pytorch-gpu\n",
    " accuracy=0\n",
    "        if  (worker_rank == 0):\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "# LSTM | dnn_1_lstm | https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/ \n",
    " if worker_rank == 0:\n",
    "\n",
    "            # Validation\n",
    "            if epoch % 100 != 0:\n",
    "                continue\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # tensor.detach().cpu().numpy()\n",
    "                y_pred = model(X_train)\n",
    "\n",
    "                tmp_data_rmse = criterion(y_pred, y_train)\n",
    "                tmp_data_rmse = tmp_data_rmse.cpu()                 # Move to CPU\n",
    "                train_rmse = np.sqrt(tmp_data_rmse)\n",
    "\n",
    "                y_pred = model(X_test)\n",
    "\n",
    "                tmp_data_rmse = criterion(y_pred, y_test) \n",
    "                tmp_data_rmse = tmp_data_rmse.cpu()                 # Move to CPU          \n",
    "\n",
    "                test_rmse = np.sqrt(tmp_data_rmse)                  # Für Ausgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efa896-cae9-40b1-b953-dd3ee89a8507",
   "metadata": {},
   "source": [
    "# 3. Details zu den Datasets und Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf198c0-f1fa-4a76-87c7-496ded29f936",
   "metadata": {
    "tags": []
   },
   "source": [
    "Das PyTorch Dataset ermöglicht das einfache Umgehen  mit den Daten. Die Funktion braucht 3 Methoden: `__init__`, `__len__` und `__getitem__`. In der init Methode kann man z.B. die Daten nochmal verändern oder von dort aus laden. \n",
    "\n",
    "Ohne ein Dataset können Daten so direkt geladen werden: `Train_loader = DataLoader(torch.utils.data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)`.<br>\n",
    "Es ist leicht und schnell erledigt. Man kann auch ein eigenes PyTorch Dataset erstellen. Beispiele dazu folgen.\n",
    "\n",
    "Der Dataloader wird beim Training genutzt und hat Zugriff auf das Dataset.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "PyTorch Dataset und Dataloader: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#loading-a-dataset  <br>\n",
    "PyTorch Dataloader https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da8158ed-fb96-4cff-b669-b69ad615c68b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Daten können auch mit dem Client über das Netzwerk verteilt werden. Geht gut mit kleinen Daten zum testen.\n",
    "# - data kann ein Array sein, ein Dataset, Pandas DataFrame, ... \n",
    "client.scatter(data, broadcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93730bd3-a8dd-4e92-99aa-206ae328c7ed",
   "metadata": {},
   "source": [
    "Das Laden und Verarbeiten der Daten kann als Funktion ausgelagert werden. Dort (oder im Dataset) kann vom HDFs gelesen werden.<br>\n",
    "\n",
    "<u>Hinweis:</u><br>\n",
    "Wenn es zu einem Pickelerror kommt, müssen bestimmte Klassen und Funktionen in eine .py Datei geschrieben und von jedem Worker importiert werde. <br>\n",
    "Dateien können mit `client.upload_file('myfile.py')` hochgeladen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5cac77-64f1-4216-96cc-04700121dd64",
   "metadata": {},
   "source": [
    "## 3.1 Eigenes PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d19f2-4e5c-4501-9f0e-d8ddfa6b592f",
   "metadata": {},
   "source": [
    "Wenn wir Bilder aus dem HDFS laden wollen, müssen wir eine Funktion nutzen. Derzeit können wir den Vorteil der Datenlokalität nicht nutzen, siehe (https://dask.discourse.group/t/reading-data-and-image-data-from-hdfs-for-training/2220/2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a28922c-962e-4327-bbe7-f893720f8a23",
   "metadata": {},
   "source": [
    "# Eigenes Dataset was für das training genutzt wird.\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "       Lade Daten...\n",
    "       Worker mit Rang n und IP m soll diese Daten laden... \n",
    "       Einstellungen...\n",
    "    \n",
    "    def __len__(self):\n",
    "        Gebe Länge der Daten zurück\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Verändere Daten ggf. \n",
    "        # .... \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2be33e-baf0-4bd1-8e00-4f4cf86f78f8",
   "metadata": {},
   "source": [
    "Das Beispiel zeigt, wie man derzeit Bilddaten aus dem HDFs laden könnte. \n",
    "\n",
    "Als erstes listen wir alle Pfade auf, danach laden wir die Bilder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a349a805-2b8c-4900-9e40-6660738bdfdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liste alle Pfade der Bilder auf.\n",
    "def get_filenames(fs): \n",
    "    \n",
    "    classes =['dog', 'chicken']   # Klassen dir wir haben (und auch verzeichnisse) \n",
    "    data = []\n",
    "    file_location = []\n",
    "    # HDFs verbindung\n",
    "    hdfs = fs.HadoopFileSystem(\"hdfs://sun.bigdata.fh-aachen.de\", port=9000, user=\"schechtel\")\n",
    "        \n",
    "    for i in classes:\n",
    "        files = hdfs.get_file_info(fs.FileSelector(f'/project/schechtel/animals/{i}')) # Pro Verzechniss werden alle Pfade aufgelistet. \n",
    "        print(f\"Class: {i} \\t items: {len(files)}\")\n",
    "        for path in files:\n",
    "            data.append([path.path, i])  # Data: [...PNG , Klasse Dog]\n",
    "            \n",
    "    np.random.shuffle(data) # Shuffle\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecbdac8a-13b4-436d-85a0-f086600ce2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "# Dataset\n",
    "class create_trainset(Dataset):\n",
    "    def __init__(self, data_paths):  \n",
    "        \"\"\"\n",
    "        data_paths: Die Pfade die mit get_filenames ermittelt wurde.\n",
    "        - Könnte auch hier gemacht werden... \n",
    "        \"\"\"\n",
    "        self.data_paths = data_paths  # Data: [...PNG , Klasse Dog]\n",
    "        self.hdfs = fs.HadoopFileSystem(\"hdfs://sun.bigdata.fh-aachen.de\", port=9000, user=\"schechtel\")  # HDFS  Verbindung \n",
    "        # Sonstige Angaben... \n",
    "        self.img_dim    = (32, 32) # 227\n",
    "        self.transform = transforms.Compose(\n",
    "                           [transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] )\n",
    "        self.class_map = {'dog':0, 'chicken': 1}\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)  # Länge des Datasets \n",
    "\n",
    "    def __getitem__(self, idx):      # Iteriere mit idx:   __getitem__(idx)\n",
    "         \n",
    "        img_path, class_name = self.data_paths[idx]    # img_path=...PNG,  class_name=... dog\n",
    "\n",
    "        loded_image = skimage.io.imread( self.hdfs.open_input_file(img_path) )\n",
    "        img = Image.fromarray(np.uint8(loded_image)) \n",
    "        img = fn.center_crop(img, self.img_dim) \n",
    "        img = self.transform(img) \n",
    "        \n",
    "        class_id = self.class_map[class_name]   # dog => 0\n",
    "        \n",
    "        img_tensor = torch.from_numpy(np.asarray(img).copy())\n",
    "        \n",
    "        class_id = torch.tensor([class_id]) \n",
    "\n",
    "        return img_tensor, class_id \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24061cd6-a225-4c25-b9d7-dad8082489c7",
   "metadata": {},
   "source": [
    "Wenn die Daten lokal auf dem Rechner sind, könnte das Laden der Daten so aussehen wie unten. <br>\n",
    "Im Dataset ermitteln wir mittels Python alle Bildnamen und Pfade.\n",
    "\n",
    "Im Dataset können auch Subsets von Pfaden für veschiedene Worker erstellt werden, oder auch Datasets für das Testen. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "075ad3cd-8939-47c7-b70e-78dde7450629",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "##-- HDFS --##\n",
    "##-- HDFS --##\n",
    "from pyarrow import fs\n",
    "files_list = get_filenames(fs)\n",
    "hdfs = fs.HadoopFileSystem(\"hdfs://sun.bigdata.fh-aachen.de\", port=9000, user=\"schechtel\") # get hdfs\n",
    "files = hdfs.get_file_info(fs.FileSelector('/project/schechtel/')) # get all files in hdfs dir\n",
    "# Prior attempt to load libhdfs failed\n",
    "##-- HDFS --##\n",
    "##-- HDFS --##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f2b014-bdf3-4a55-a81a-805232d3631a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mask_dataset_func.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mask_dataset_func.py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from PIL import Image\n",
    "import skimage\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "class mask_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.classes=['with_mask','without_mask']             # 2 Klassen\n",
    "        self.class_map={'with_mask':0, 'without_mask':1 }\n",
    "        self.dir=\"01work/Datasets/facemask/archive/\"          # ../archive/with_mask  |  ../archive/without_mask  \n",
    "        self.img_paths=[]\n",
    "        \n",
    "        for klass in self.classes:\n",
    "            tmp_list = os.listdir(f\"{self.dir}{klass}\")   # os.listdir(): Liste Verzeichniss auf und gebe als Liste zurück \n",
    "            print(f\"Klasse: {klass}, Items: {len(tmp_list)}\")\n",
    "            for path in tmp_list:\n",
    "                self.img_paths.append([f\"{self.dir}{klass}/{path}\", self.class_map[klass]]) #   [....PNG , with_mask => 0 ]\n",
    "        print(f\"Gesamte Items: {len(self.img_paths)}\")    \n",
    "        \n",
    "        # Shuffle...\n",
    "        # worker n soll diese Pfade Pfade bekommen... \n",
    "        # Testimg = ...\n",
    "                \n",
    "    def __len__(self):\n",
    "          return len( self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = skimage.io.imread( self.img_paths[idx][0] )\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img_tensor = torch.from_numpy(np.asarray(img).copy())\n",
    "        \n",
    "        return img_tensor, torch.tensor(int(self.img_paths[idx][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1360b0d3-4263-493e-aaf9-a393e7d0254f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Schreibe Datei und lade es hoch.\n",
    "client.upload_file(\"mask_dataset_func.py\")\n",
    "import mask_dataset_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80e2c37-c90a-4ab0-86a6-66151e6c65ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker count: 2\n",
      "Start training\n",
      "\n",
      "Done\n",
      "Done\n",
      "Time elapsed: 62.014142990112305\n",
      "16.11.2023  17:42:5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def do_train():\n",
    "    pub_stats   = Pub(\"my_channel\")                \n",
    "    worker_rank = int(dist.get_rank())                  # Globaler Rank\n",
    "    worker_ip   = os.getenv('WORKER_HOST')              # Worker IP\n",
    "    # Mit Python können auch andere Merkmale wie Hostname ermittelt werden. \n",
    "    \n",
    "    dataset = mask_dataset_func.mask_dataset()  # Ggf. mit Parameter \n",
    "    sampler = DistributedSampler(dataset)  # Iterationen auf Worker aufteilen \n",
    "    loader = DataLoader(dataset, batch_size=16, sampler=sampler, num_workers=2, prefetch_factor=4, pin_memory=True ) # sampler=sampler, num_workers=2, prefetch_factor=4, pin_memory=True \n",
    "    \n",
    "    \n",
    "    for epoch in range(2): \n",
    "        sampler.set_epoch(epoch)\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            X = batch_x\n",
    "            y = batch_y\n",
    "            if i%10==0:\n",
    "                print(i)\n",
    "            if i==100:\n",
    "                break\n",
    "    \n",
    "    msg = \"Done\"\n",
    "    pub_stats.put({\"msg\": msg}) \n",
    "\n",
    "    \n",
    "pytorch_tools.run(do_train, client) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168adfec-a64d-4c1c-8379-60346ee480ae",
   "metadata": {},
   "source": [
    "### 3.3.1 Auswirkung des Distrubuted Samplers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf3387-eec5-43f9-b98c-9130903f3226",
   "metadata": {},
   "source": [
    "Wir haben also ein Dataset. Wenn wir diese Daten nicht mit dem Sampler aufteilen, verhält es sich als wäre es nur ein Worker. Teilen wir diese Daten unter den Workern auf (Data Parallel), so ist das Training schneller beendet.\n",
    "\n",
    "Bekommen die Worker durch diese Aufteilung zu wenig Daten, dann ist die Genauigkeit am Ende viel schlechter. Für eine bestimmte Menge an Daten sollten nicht zu viele Worker beteiligt sein, wenn die Daten pro Worker am Ende gering sind.\n",
    "\n",
    "Wie gut die Genauigkeit am Ende ist, liegt an vielen Faktoren. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d8fabb4-e5df-45c0-82e0-737d5caed539",
   "metadata": {},
   "source": [
    "sampler = DistributedSampler(trainset) # Übergebe Dataset\n",
    "loader = DataLoader(trainset, batch_size=batch_size, sampler=sampler) # Setze Sampler\n",
    "...\n",
    "for epoch  in epoches:\n",
    "   sampler.set_epoch(epoch)\n",
    "   ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a989f8-115c-4eff-b19e-220b9b7dcafe",
   "metadata": {},
   "source": [
    "Wenn sich die lokalen Daten pro Worker unterscheiden, ist ein Sampler nicht notwendig.\n",
    "\n",
    "Wenn alle Worker gleiche Daten haben (wie das Cifar10 Dataset), dann werden die Iterationen aufgeteilt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbb51b-4d28-42c5-88d0-2cd3abfd1511",
   "metadata": {},
   "source": [
    "Länge eines Trainsets: `trainset.__len__()`<br>\n",
    "Länge des Samplers: `len(sampler)` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1c4e0-2e1e-49be-bbe3-fc7698f59940",
   "metadata": {},
   "source": [
    "Worker: 6, ohne Sampler <br>\n",
    "<img src=\"./pictures/samplertrain_1.PNG\" >\n",
    "\n",
    "Worker: 6, mit Sampler<br>\n",
    "<img src=\"./pictures/samplertrain_2.PNG\" >\n",
    "\n",
    "Worker: 3, mit Sampler<br>\n",
    "<img src=\"./pictures/samplertrain_3.PNG\" >\n",
    "\n",
    "Worker: 2, mit Sampler<br>\n",
    "<img src=\"./pictures/samplertrain_4.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec15ff9-e259-4e52-83a5-70f173025e87",
   "metadata": {},
   "source": [
    "Diese waren einfache Evaluierungen, die während des Trainings wie oben gemacht wurden. <br>\n",
    "Am Ende ist die Genauigkeit nach dem Evaluieren tendenziell besser. <br>\n",
    "Bei 3 Nodes die während des Trainings evaluiert wurden, lag die Genauigkeit bei 15,2%. Am Ende das Evaluieren mit dem Testset 45%.\n",
    "\n",
    "Mit der Evaluierung mit dem Trainset ergab sich ein Verlust von 9% der Genauigkeit von 1 bis 3 Nodes. Dabei lieferte das Trainieren mit nur einen Node die bessere genauigkeit, dauerte auch am längsten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9cdd4-892f-4ecc-9620-8d0e2bb59277",
   "metadata": {},
   "source": [
    "# 4. Model Laden und Evaluieren "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0afbd13-3606-42ea-895d-5be8c5ca6869",
   "metadata": {},
   "source": [
    "Nachdem wir das Model trainiert und gespeichert haben, können wir es laden. Für das Laden können wir eine GPU oder CPU nutzen. Das Netzwerk sollte beim Laden verfügbar sein.\n",
    "\n",
    "<u>Hinweis bei der CPU Nutzung:</u> <br>\n",
    "Trotz dem mappen der Lokation mit `.cpu()`  kann ein GPU Device automatisch ausgewählt werden, was zu einer Fehlermeldung führt: <br>\n",
    "\"module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu\"<br>\n",
    "Um das zu umgehen, falls sowas auftritt, sollte keine GPU aktiv sein. Ist keine GPU vorhanden, sollten diese Fehler nicht auftreten. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e4724-130e-444d-86c5-f6f9bc2dbae6",
   "metadata": {},
   "source": [
    "## 4.1 Model CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58265829-132f-4359-823d-3d5bf085d978",
   "metadata": {},
   "source": [
    "Hier erstellen wir ein Testset, um das trainierte Model zu evaluieren. Das Testset ist wieder ein eigenes Dataset, was erstellt werden kann. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6990e41-8f42-4e58-9dce-3fce6853c583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:09<00:00, 18939153.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Cifar10 Testset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# Dataloader                                     \n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False)\n",
    "                                         \n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1e481-1f1f-413d-878a-5f8b737c3dd1",
   "metadata": {},
   "source": [
    "Wenn beim Speichern weitere Parameter übergeben wurde wie \"epoch=epoch\", können diese aus dem Checkpoint gelesen werden.<br>\n",
    "`checkpoint.keys()` gibt die verfügbaren Schlüssel an, wenn es ein Checkpoint ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6d422c8-571f-4c18-ad4c-b98d74bbe302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########### GPU ###############\n",
    "\n",
    "model = torch.nn.DataParallel( Model().cuda() ) #Wrap als DP wenn nötig. \n",
    "\n",
    "#model      = Model().cuda()\n",
    "checkpoint = torch.load(\"DDPmodel.ckpt\")                # Lade Ckpt \n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])   # Lade Dict in das Model \n",
    "epoche     = checkpoint['kwargs']['epoch']              # Lade Sonstiges... R\n",
    "\n",
    "## Sonstiges falls übergeben. Z.B.: \n",
    "#  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#  optimizer.load_state_dict(checkpoint['kwargs']['optimizer_state_dict'])\n",
    "#  loss = checkpoint['kwargs']['loss']\n",
    "\n",
    "## Wenn Endung .pt:\n",
    "#   modelpt = torch.load(\"DDPmodel.pt\")   # Dict darin enthalten             \n",
    "#   model.load_state_dict(modelpt)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a24353e9-c024-4063-aab8-c88e658980ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Das sollte dann funktionieren\n",
    "images_gpu = images.to('cuda') # Oder device wählen\n",
    "outputs = model(images_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daef561-ed64-4846-80ec-d2aaf9a83a19",
   "metadata": {},
   "source": [
    "Dasselbe mit CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9984323-da34-4f8e-b405-0ba358299eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### CPU ###############\n",
    "### Auf CPU Cluster getestet, es funktioniert ### \n",
    "\n",
    "model = torch.nn.DataParallel( Model().cpu()  ) # Wrap als DP wenn nötig. \n",
    "\n",
    "#model      = Model().cpu()\n",
    "# Lade Model als Checkpoint \n",
    "checkpoint = torch.load( \"DDPmodel.ckpt\", map_location=torch.device('cpu') )\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])   # Lade Dict in das Model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b76bcc43-f8e8-4a56-b93a-1bfd8edac960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dann sollte das funktionieren:\n",
    "images_cpu = images.to('cpu')\n",
    "outputs = model(images_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726bcae4-fdcd-40e0-ba0a-d2beaec53bdc",
   "metadata": {},
   "source": [
    "Nach dem Laden können wir das Model so nutzen wie wir es wollen.\n",
    "\n",
    "Die unteren Beispiele sind aus PyTorch. Wir überprüfen die Accuracy.  Die Predictions können auf GPU oder CPU laufen.\n",
    "\n",
    "<br>\n",
    "\n",
    "Test the network on the test data: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#test-the-network-on-the-test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9b63cb-278f-48e5-82b3-8655b09a5ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 50 %\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Example on website https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        \n",
    "        images = images.cuda()      # CUDA for GPU usage  \n",
    "        labels = labels.cuda()      # CUDA for GPU usage \n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9925a-53d9-4afe-8c1b-01bd808f8ce6",
   "metadata": {},
   "source": [
    "Das Trainieren mit 1 bis 3 Nodes ergab folgendes: <br>\n",
    "Node 1:  55% <br>\n",
    "Node 2:  50% <br>\n",
    "Node 3:  46% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a154239-4308-404d-82a1-2b57bff0190a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 46.4 %\n",
      "Accuracy for class: car   is 82.9 %\n",
      "Accuracy for class: bird  is 24.6 %\n",
      "Accuracy for class: cat   is 23.4 %\n",
      "Accuracy for class: deer  is 40.2 %\n",
      "Accuracy for class: dog   is 43.2 %\n",
      "Accuracy for class: frog  is 51.6 %\n",
      "Accuracy for class: horse is 53.5 %\n",
      "Accuracy for class: ship  is 60.8 %\n",
      "Accuracy for class: truck is 40.8 %\n"
     ]
    }
   ],
   "source": [
    "## Weitere Möglichkeit\n",
    "\n",
    "# Pytorch Example on website https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# prepare to count predictions for each class\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "\n",
    "        images = images.cuda()      # CUDA for GPU usage \n",
    "        labels = labels.cuda()      # CUDA for GPU usage \n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec60aa95-ed5d-4340-8769-e12b9f02e2f0",
   "metadata": {},
   "source": [
    "## 4.2 Weiteres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9742c-e445-407c-a8d4-92f7aa5a2aa3",
   "metadata": {},
   "source": [
    "Die ganze Evaluierung kann in Funktionen ausgelagert und vereinfacht werden.<br>\n",
    "Mit Torchmetric kann die Evaluierung vereinfacht werden und mehr. \n",
    "\n",
    "Um mehr Übersicht zu haben, kann auch das TensorBoard von TensorFlow für PyTorch eingesetzt werden.\n",
    "\n",
    "<br>\n",
    "\n",
    "WELCOME TO TORCHMETRICS: https://torchmetrics.readthedocs.io/en/stable/ <br>\n",
    "TORCHMETRICS Beispiel: https://lightning.ai/docs/pytorch/stable/ecosystem/metrics.html <br>\n",
    "TORCH.UTILS.TENSORBOARD: https://pytorch.org/docs/stable/tensorboard.html"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02f43b87-74e7-48c3-8f0d-262375bacee6",
   "metadata": {},
   "source": [
    "## So kann das Evaluieren mit torchmetrics aussehen.:\n",
    "#  - PyTorch Lightning Beispiel: https://lightning.ai/docs/pytorch/stable/ecosystem/metrics.html\n",
    "\n",
    "!pip install torchmetrics   # Einfache installation und sofort anwendbar. \n",
    "import torchmetrics\n",
    "\n",
    "device = torch.device('cuda')\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        \n",
    "        images = images.cuda()   \n",
    "        labels = labels.cuda()    \n",
    "\n",
    "        outputs = model(images)\n",
    "        acc = metric(outputs, labels)\n",
    "        \n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")\n",
    "\n",
    "# Resetting internal state such that metric ready for new data\n",
    "metric.reset()\n",
    "\n",
    ">>\n",
    ">> Accuracy on all data: 0.4674000144004822\n",
    ">>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922b385-a404-4895-8469-f58e2c541e9c",
   "metadata": {},
   "source": [
    "# 5. Andere Netzwerke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d4ef6-e88c-411c-9c42-bda42f331c92",
   "metadata": {},
   "source": [
    "Das was gemacht haben, geht auch mit größeren Netzwerken wie AlexNet. Um es schlicht zu halten, nutzen wir wieder das Cifar10 Dataset.\n",
    "\n",
    "Bei größeren Netzen nutzen wir den <u>PowerSGD Hook</u>, um die Kommunikation über Maschienen zu verbessern. Das Beschleunigt das Training.<br>\n",
    "Es kann auch `torch.autocast()` genutzt werden, um Daten in ein anderes Format zu bringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9a1cb21-e21f-411a-864c-769f8d01b1bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AlexNet: https://blog.paperspace.com/alexnet-pytorch/\n",
    "\n",
    "##- AlexNet Beispiel -## \n",
    "# - Klassen: 10 \n",
    "# Unser AlexNet.:\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #with torch.autocast(device_type='cuda', dtype=torch.float16):  \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbe978-acc2-4eb7-a03d-386c42abd5c4",
   "metadata": {},
   "source": [
    "Um den Hook zu nutzen:<br>\n",
    "`model = pytorch_tools.register_DDP_PowerSGD_hook(model, device_id, matrix_approximation_rank:int=12, start_powerSGD_iter:int=2)`\n",
    "\n",
    "matrix_approximation_rank steuert die Kompression. Fange mit dem Wert 2 an und erhöhe immer um 2. start_powerSGD_iter fängt bei 2 an und kann jeweils erhöht werden. Man kann verschiedene Einstellungen testen, auch verschiedene Batchgrößen. \n",
    "\n",
    "Momentan steht matrix_approximation_rank auf 12 und start_powerSGD_iter auf 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dd35d58-acfc-4291-9a42-c90c397a3de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Trainingsfunktion die jeder Worker ausführt. \n",
    "\n",
    "def train():\n",
    "    \n",
    "    pub_stats  = Pub(\"my_channel\")                          # Channel für Nachrichten              \n",
    "    worker_rank = int(dist.get_rank())                      # Globaler Rank\n",
    "    worker_ip = os.getenv('WORKER_HOST')                    # Worker IP\n",
    "    device_id = worker_rank % torch.cuda.device_count()\n",
    "    \n",
    "    device = torch.device(\"cuda\")  # 'cuda': Nutze alle GPUs | 0: nutze GPU 0 | 'cpu': Nutze CPU, Backend auf gloo stellen | \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  \n",
    "    num_epochs = 5     \n",
    "    batch_size = 256   \n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465],\n",
    "            std=[0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform) \n",
    "    sampler = DistributedSampler(trainset)\n",
    "    loader = DataLoader(trainset, batch_size=batch_size, sampler=sampler, num_workers=2, prefetch_factor=4, pin_memory=True ) \n",
    "    \n",
    "    model = AlexNet().to(device)\n",
    "    model = DDP(model,  device_ids=[device_id], bucket_cap_mb=40)  # bucket_cap_mb=40, mixed_precision=\"fp16\"\n",
    "    \n",
    "    ##  - Nutze Hook: - ##\n",
    "    # - Paramater: model, device_id, matrix_approximation_rank:int=12, start_powerSGD_iter:int=2\n",
    "    #model = pytorch_tools.register_DDP_PowerSGD_hook(model, device_id)   # SGD Hook, Model wird dort auch in DDP umgewandelt. \n",
    "    model = pytorch_tools.register_fp16_compress_wrapper_SgdPower_hook(model, device_id)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    ## - Kann einen verteilten Optimierer nutzen. Dann aber keinen anderen Hook. - ##\n",
    "    # - register_distOpt_PostLocalSGDOpt(model,  device_id, local_optim, period:int=4, warm_up:int=100)\n",
    "    #model, optimizer = pytorch_tools.register_distOpt_PostLocalSGDOpt(model, device_id, optimizer)\n",
    "    \n",
    "    #scaler= torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        # this ensures the data is reshuffled each epoch, if using sampler. \n",
    "        sampler.set_epoch(epoch)\n",
    "         \n",
    "        correct = 0\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #with torch.autocast(device_type='cuda', dtype=torch.float16):    \n",
    "            outputs = model(batch_x.to(device))                     \n",
    "            loss = criterion(outputs, batch_y.to(device))\n",
    "            \n",
    "            # PyTorch DDP Gradient AllReduce\n",
    "            loss.backward()\n",
    "            #scaler.scale(loss).backward()\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            #scaler.step(optimizer)\n",
    "            #scaler.update()\n",
    "            \n",
    "           # with torch.autocast(device_type='cuda', dtype=torch.float16):  # new\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if torch.cuda.is_available():\n",
    "                   correct += (predicted.cpu() == batch_y.cpu()).sum()\n",
    "            else:\n",
    "                   correct += (predicted == batch_y).sum()\n",
    "            accuracy = 100 * correct / len(trainset)\n",
    "\n",
    "        if worker_rank == 0: # jede Epoche\n",
    "            msg = f\"loss: {round(loss.item(), 4)} acc: {accuracy}  epoche: ({epoch+1}/{num_epochs})\"\n",
    "            pub_stats.put({\"msg\": msg})\n",
    "            pytorch_tools.ddp_save_model_dict(pub_stats, model.state_dict(), \"./DDPmodel_ALexNet\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f1f4130-5191-456b-a448-ac153ee2f561",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker count: 2\n",
      "Start training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Pin memory thread exited unexpectedly\n",
      "Traceback (most recent call last):\n",
      "  File \"/rapids/notebooks/01work/final_work/pytorch_dispatcher_resulthandler.py\", line 325, in _get_results\n",
      "    fut.result()\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/client.py\", line 314, in result\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/tmp/dask-worker-space/worker-w5jys_e0/pytorch_dispatcher_resulthandler.py\", line 245, in dispatch_with_ddp\n",
      "    val = pytorch_function(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_12597/614650358.py\", line 48, in train\n",
      "    for i, (batch_x, batch_y) in enumerate(loader):\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/conda/envs/rapids/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1290, in _get_data\n",
      "    raise RuntimeError('Pin memory thread exited unexpectedly')\n",
      "RuntimeError: Pin memory thread exited unexpectedly\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12597/2858130547.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpytorch_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/rapids/notebooks/01work/final_work/pytorch_tools.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(train, client, date_time_hour_offset, pytorch_mode, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mrh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time elapsed: {time.time() - time_start}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rapids/notebooks/01work/final_work/pytorch_dispatcher_resulthandler.py\u001b[0m in \u001b[0;36mprocess_results\u001b[0;34m(self, futures, raise_errors)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rapids/notebooks/01work/final_work/pytorch_dispatcher_resulthandler.py\u001b[0m in \u001b[0;36m_get_results\u001b[0;34m(self, futures, raise_errors)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;31m# Dask:   wait(fs[, timeout, return_when])      Wait until all/any futures are finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;31m# Read here: https://distributed.dask.org/en/stable/api.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m   4995\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_timedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4996\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4997\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_when\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4998\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pytorch_tools.run(train, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814b772-284e-480a-8c54-728e6de4e890",
   "metadata": {},
   "source": [
    "Folgendes wurde erfasst:<br>\n",
    "Node 1: 199s, acc: 60% Evaluiert  <br>\n",
    "Node 2: 127s, acc: 54% Evaluiert  <br>\n",
    "Node 3: 104s, acc: 47% Evaluiert\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aeff11b-4057-46ca-8f2c-cc1d928fa0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465],\n",
    "            std=[0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)                                     \n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False)\n",
    "                                         \n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333bf188-50cb-4350-a444-82ff9c0222f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.DataParallel( AlexNet().cuda() )\n",
    "model.load_state_dict(torch.load(\"DDPmodel_ALexNet.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03ee7d2e-c00d-469f-bbad-927c28545c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "CPU times: user 1min 57s, sys: 51.2 ms, total: 1min 57s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Pytorch Example on website https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "\n",
    "        images, labels = data\n",
    "        \n",
    "        images = images.cuda()      # CUDA for GPU usage  \n",
    "        labels = labels.cuda()      # CUDA for GPU usage \n",
    "\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57ffd7-5e02-4906-a4fb-6da326d727ce",
   "metadata": {},
   "source": [
    "Es kann auch die Zeit gemessen werden, ob die Einfachheit von torchmetrics auch schneller ist. <br>\n",
    "In diesem Versuch mit Cifar10 hat das Evaluieren mit torchmetrics nur knapp 0,7s länger gedauert. Viele Faktoren können eine Auswirkung haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "695cb027-2331-41c6-88b6-0a5d0d8e227d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on all data: 0.4846999943256378\n",
      "CPU times: user 2min 4s, sys: 39.5 ms, total: 2min 4s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import torchmetrics\n",
    "device = torch.device('cuda')\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        \n",
    "        images = images.cuda()   \n",
    "        labels = labels.cuda()    \n",
    "\n",
    "        outputs = model(images)\n",
    "        acc = metric(outputs, labels)\n",
    "        \n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")\n",
    "\n",
    "# Resetting internal state such that metric ready for new data\n",
    "metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "590e67fb-3e20-44ec-8ee8-5e43927695e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198e6fb-cc34-4b47-9507-48a2f4c9a95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba41fa-868f-4db0-ac3f-ef2dc4618c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f333d-8939-4732-b143-51076d06358d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f22c83-a686-4fff-b41e-83d164b7a560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
