{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5104892b-2040-40fb-bf75-03cf040a31e4",
   "metadata": {},
   "source": [
    "# Pytorch Deep-Learning | Model-Parallel | Docker \n",
    "***********\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddbea8a-5405-4730-9ea2-8a3580c71341",
   "metadata": {},
   "source": [
    "In diesem Notebook wird vorgeführt, wie man das Model auf GPUs aufteilt und trainiert. Dafür gibt es einige Möglichkeiten, wie man sowas realisieren kann. Wir nutzen Dask als Cluster.\n",
    "\n",
    "Um das Model über Maschinen hinweg zu verteilten, müssen wir RPC (Remote Procedure Call) und RReF (Remote Reference) nutzen. Das kann hier und da etwas schwierig sein.\n",
    "\n",
    "<br>\n",
    "PyTorch Model-Parallel: <br>\n",
    "\n",
    "Mit RPC können wir remote Funktionen und Aufgaben ausführen, wie z.B. dass ein Teilnetzwerk etwas berechnet. Wenn wir sagen, dass Worker:2 das Teilnetz Net2 ausführen soll, geben wir auch die Daten mit. Als Ergebnis bekommen wir eine Referenz (RReF) zu einem Objekt. Um das Ergebnis zu holen, wird es kopiert und gesendet. Die Trainingsroutine unterscheidet sich etwas von dem normalen Vorgehen. \n",
    "\n",
    "Die Kommunikation läuft im Hintergrund. Als Benutzer kann man dazu auch einiges einstellen. Der Benutzer entscheidet selber, wie das Netzwerk aufgeteilt wird.\n",
    "\n",
    "\n",
    "Wenn alle Worker auf einer Maschine sind (Single-Node Model Parallel), reduziert sich der Aufwand der Einstellungen und Kommunikation, da PyTorch alles selber macht. Wir betrachten den Fall, dass wir das Model <u>über Nodes</u> aufteilen. \n",
    "\n",
    "Um es unter CPU laufen zu lassen, siehe weiter unten.\n",
    "\n",
    "\n",
    "<u>Wann sollte Model-Parallel genutzt werden?</u><br>\n",
    "- Das Model ist groß und passt nicht auf eine GPU.\n",
    "- Das Model kann vertikal zerteilt werden.\n",
    "- Mehrere GPUs sind lokal verfügbar (einfaches setup), oder über Maschinen (mehr Konfigurationsaufwand).\n",
    "- Hier wird das Model vertikal aufgeteilt (in Layers oder Teilnetze) deren Output zur nächsten Node via PyTorch RPC als Input genommen wird.\n",
    "\n",
    "\n",
    "Als Basis für die Verteilung und Ausführung von Funktionen auf andere Dask-Worker, stellt Saturncloud Module bereit, die für Dask-PyTorch-DDP genutzt werden. <br>\n",
    "Mit Anpassungen können damit auch andere Probleme wie Model-Parallel gelöst werden. Die Konfigurationen und Verteilung laufen im Hintergrund. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Dask und Dask.distributed sollten die gleiche Version haben.\n",
    "Dask: https://www.dask.org && https://docs.dask.org/en/stable/ <br>\n",
    "PyTorch: https://pytorch.org  <br>\n",
    "PyTorch releases: https://github.com/pytorch/pytorch/releases <br>\n",
    "Dask-PyTorch-DDP Open Source Module von Saturncloud: https://github.com/saturncloud/dask-pytorch-ddp/tree/main <br>\n",
    "PyTorch RPC und RReF: https://pytorch.org/docs/stable/rpc.html <br>\n",
    "DISTRIBUTED RPC FRAMEWORK: https://pytorch.org/docs/stable/rpc.html#distributed-rpc-framework <br>\n",
    "PyTorch SINGLE-MACHINE MODEL PARALLEL BEST PRACTICES: https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html <br>\n",
    "DISTRIBUTED PIPELINE PARALLELISM USING RPC: https://pytorch.org/tutorials/intermediate/dist_pipeline_parallel_tutorial.html#step-1-partition-resnet50-model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd2246-c590-4924-a11e-b679ea78c8ea",
   "metadata": {},
   "source": [
    "# 1. Aufbau und Möglichkeiten "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea79117-3d57-4af7-bd6b-4f0830ad96d5",
   "metadata": {},
   "source": [
    "Es gibt verschiedene Möglichkeiten Model-Parallel zu realisieren. Wir werden uns auf ein fokussieren. Das Netzwerk wird Vertikal aufgeteilt.\n",
    "\n",
    "Das allgemeine Trainieren kann man in 4 Bereiche aufteilen. Das Bild zeigt Bereiche, angelent an die Flynn-Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e1f05-2608-43e5-8f86-c3124d12790e",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/rapids_flynn.PNG\"  width=\"625px;\" hight=\"625px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c2555-c5bc-44f8-ac48-7f983651f898",
   "metadata": {},
   "source": [
    "Wir importieren Dateien, die Klassen und Funktion erhalten, um die Benutzung zu vereinfachen.\n",
    "\n",
    "In den Modulen selber können Einstellungen vorgenommen werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00af9a6-f4b9-4ad8-9ebc-de2a06ac521d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools 1.0 | Setze Umgebungsvariablen\n",
      "PYTORCH_DIST_BACKEND: nccl\n",
      "PYTORCH_DIST_DDP_PORT: 23456\n",
      "NCCL_SOCKET_NTHREADS: 4\n",
      "NCCL_NSOCKS_PERTHREAD: 2\n",
      "PYTORCH_MODULE_LOG: True\n",
      "\n",
      "RPC Config:\n",
      "GLOO_SOCKET_IFNAME: eno1, NCCL_SOCKET_IFNAME: eno1\n",
      "TP_SOCKET_IFNAME: eno1    , START_ON_RANK: 0\n",
      "PyTorch Dispatcher-/Resulthandler 1.0\n"
     ]
    }
   ],
   "source": [
    "## Tools um die Nutzung zu vereinfache\n",
    "# - Das Modul selber imortiert auch pytorch_dispatcher_resulthandler\n",
    "import pytorch_tools as pytorch_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d6636-a9b8-4e12-86d7-1c1da8b700f0",
   "metadata": {},
   "source": [
    "Damit die Kommunikation funktioniert, muss in dem Modul `pytorch_tools.py` das Netzwerkinterface eingestellt werden. In diesem Aufbau hießt das Interface \"eno1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d73732-99e5-4cb5-90db-7e84c6c961da",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./pictures/ptmp_rpc.PNG\"  width=\"365px;\" hight=\"265px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed25de0-1f62-4955-b33e-d5723dd5d44b",
   "metadata": {},
   "source": [
    "Das obere Bild zeigt einen Ausschnitt des Moduls pytorch_tools.py, hier muss das richtige Interface eingestellt werden. Das Interface wird dann von allen Worker für die Kommunikation genutzt. \n",
    "\n",
    "`PYTORCH_MODEL_PARALLEL__START_ON_RANK` gibt an, welcher Worker nach Rang die Trainingsfunktion ausführen soll. Mehr dazu später."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a9ff981-978a-4e57-8da0-8230f1833412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- In Entwicklung -- # \n",
    "# Code für PyTorch Model-Parallel\n",
    "#import pytorch_dispatcher_resulthandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b60c576-963e-4790-8184-74491dab9192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client-IP: 127.0.0.1:8786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-be323759-86a8-11ee-8059-a4bb6d4fbfd8</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"http://127.0.0.1:8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-0837784d-0bdc-4419-8e70-f563a3c2bf68</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://149.201.182.203:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 3\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://149.201.182.203:8787/status\" target=\"_blank\">http://149.201.182.203:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 3\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> 3 minutes ago\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 187.58 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: tcp://149.201.182.188:39059</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://149.201.182.188:39059\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://149.201.182.188:40277/status\" target=\"_blank\">http://149.201.182.188:40277/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 62.53 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://149.201.182.188:46755\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-nxytgkur\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Quadro RTX 5000\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 6.0%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 412.71 MiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 16.20 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 1.66 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: tcp://149.201.182.203:39849</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://149.201.182.203:39849\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://149.201.182.203:35935/status\" target=\"_blank\">http://149.201.182.203:35935/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 62.53 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://149.201.182.203:36145\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-v7chjb5l\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Quadro RTX 5000\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 91.2%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 630.32 MiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 95.65 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 143.36 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: tcp://149.201.182.205:37137</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://149.201.182.205:37137\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://149.201.182.205:45355/status\" target=\"_blank\">http://149.201.182.205:45355/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 62.53 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://149.201.182.205:41021\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-ffj9o4sy\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Quadro RTX 5000\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> \n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> \n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 72.2%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 630.89 MiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 25.41 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 1.99 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://149.201.182.203:8786' processes=3 threads=3, memory=187.58 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Client \n",
    "client = pytorch_tools.create_dask_client()  # Gebe IP an. Standart:  127.0.0.1:8786 (Scheduler ist da wo auch Jupyter läuft)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb53d8a-17ed-42a0-801f-3e09d6104206",
   "metadata": {
    "tags": []
   },
   "source": [
    "Das Modul enhält Klassen, Funktionen und setzt Umbegungsvariablen, die auch andere Worker sehen müssen. Damit das kappt, muss das Modul im Cluster hochgeladen werden. <br> \n",
    "\n",
    "Wenn die Module verändert werden, müssen diese erneut hochgeladen werden. Beim Erstellen des Clients mit \"pytorch_tools.create_dask_client()\" wird die Funktion \"scatter_files()\" aufgerufen, das diese Module hochlädt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5437ce-0b59-4980-b6c8-689fb35b122a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## So werden die Module pytorch_tools.py und pytorch_dispatcher_resulthandler.py mit dem Cluster geteilt. \n",
    "#  *Bei Änderungen muss der Kernel in Jupyter neugestartet werden. \n",
    "#pytorch_tools.scatter_files(client) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cb7b2-fe28-4ee7-99fc-cb4ebc5d913e",
   "metadata": {},
   "source": [
    "Wenn wir eigene Module erstellen, können wir diese auch mit dem Cluster teilen."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b778b5b2-2163-4345-9238-2116fe2765f9",
   "metadata": {},
   "source": [
    "## Lade Datei hoch. Gibt Status aus... \n",
    "#  - ggf. müssen die Verzeichnisse angepasst werden.\n",
    "client.upload_file('myfile.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7506fac-b4b5-4c8f-a5fe-6944c8f31d27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tcp://149.201.182.188:42179', 'tcp://149.201.182.203:44877', 'tcp://149.201.182.205:36977'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zeige Schlüssel. Die Ports ändern sich. \n",
    "client.has_what().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08df2d0c-09eb-4c02-93f6-7cc510bf2f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tcp://149.201.182.188:37783', 'tcp://149.201.182.203:45847', 'tcp://149.201.182.205:42927'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starte alle Worker neu\n",
    "client.restart_workers( client.has_what().keys() )\n",
    "client.has_what().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9638818-9abe-4eb7-b261-7865cc4bb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startet client neu.\n",
    "#client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42176b6-6c38-4080-afdd-3d5adaab3137",
   "metadata": {},
   "source": [
    "Das Setup mit Docker kann so aussehen. Es gibt eine Node die Scheduler ist. Diese Node kann auch einen Worker haben. \n",
    "\n",
    "Wenn der Scheduler auch worker sein soll, muss eine zweite Konsole geöffnet werden, um den Worker zu starten. Wer am Ende Scheduler ist, ist egal, alle Knote sind gleichberechtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d83e1-ae6f-493c-8fb7-6186644bf104",
   "metadata": {},
   "source": [
    "Beispiel Setup (auf Node1 läuft auch Jupyter).: <br>\n",
    "<img src=\"pictures/cluster_setup.PNG\" width=\"925px;\" hight=\"850px;\"><br>\n",
    "Docker logo:<br>\n",
    "https://www.docker.com/company/newsroom/media-resources/![cluster_setup.png](attachment:9a543a66-02b7-4661-a8f9-a9be164d0575.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2eab78-20ec-4d3d-a5be-593096d277fd",
   "metadata": {},
   "source": [
    "Das untere Bild zeigt, wie die Aufteilung von Client, Worker und Scheduler sein könnten. Nachrichten und das Model selber werden an den Client geschickt, da von dort aus die Traningsfunktion mit Dask an die Worker submitet wird. Der Resulthandler der sich auf dem Client befindet, sammelt die Nachrichten. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ee4fd-6e3a-4bec-aa5a-023c107efadf",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/cluster_aufbau.PNG\" width=\"725px;\" hight=\"850px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b494ce-753a-43b1-aa85-40076cdc2d22",
   "metadata": {},
   "source": [
    "Das untere Bild zeigt 3 Worker, die jeweils mit dem Buchstaben `w` beginnen. Diese Namen werden bei der Initialisierung gesetzt und können durch die Namen im RPC-Kontext angesprochen werden. \n",
    "\n",
    "Dabei läuft das so ab, das w0 eine Funktion auf w1 ausführen will und als Rückgabe ein RRef bekommt. Hier vereinfach mit Frage und Antwort dargestellt.\n",
    "\n",
    "Um beim Trainieren nicht den Output erst auf die CPU zu schieben, muss ein GPU-Map erstellt werden. Dabei wird der Hinweg und Rückweg definiert. <br>\n",
    "Die Worker geben die GPU-Map in der Konsole aus, um einen Einblick zu haben. Das Erstellen wird automatisch im Hintergrund ausgeführt, jede GPU wird zu jeder anderen im Cluster gemappt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23ce0c-780d-4f51-afb8-ef46adf58cb9",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/ptmp_rpc2.PNG\"  width=\"765px;\" hight=\"665px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c17c1-d432-4b6c-9c83-b3fe29087dde",
   "metadata": {},
   "source": [
    "<u>Unter CPU:</u><br>\n",
    "Um auf CPU-Worker zu Trainieren, muss folgendes eingestellt werden:<br>\n",
    "- Im Dispatcher muss die gpu-map kommentiert werden.\n",
    "- Bei forward() muss .cuda() kommentiert werden (ggf .cpu() nutzen).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b956312f-1798-4c72-b63b-a6e1bde3e626",
   "metadata": {},
   "source": [
    "Als Erstes kommen die Importe, was fehlt, kann dazugenommen werden. Alle Knoten (falls Cluster) sollten dieselben Pakete installiert haben, möglichst mit derselben Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de8c9397-aff0-409f-9199-ba1ae42b717c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports die wir benötigen\n",
    "###########################################################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "import torchvision\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "from distributed.pubsub import Pub, Sub\n",
    "\n",
    "## RPC/RRef für Model-Parallel\n",
    "from torch.distributed.rpc import RRef \n",
    "from torch.distributed.optim import DistributedOptimizer\n",
    "import torch.distributed.autograd as dist_autograd\n",
    "from torch.distributed.rpc import init_rpc, rpc_async, rpc_sync, remote\n",
    "import torch.distributed.rpc as rpc\n",
    "\n",
    "\n",
    "# Imports für Dispatcher und Resulthandler, wird später verschwinden.\n",
    "######################################\n",
    "\n",
    "from distributed.worker import logger\n",
    "\n",
    "from distributed.client import wait, FIRST_COMPLETED, Future\n",
    "from distributed.utils import TimeoutError as DistributedTimeoutError\n",
    "from time import sleep\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import logging\n",
    "import os\n",
    "from typing import List, Optional\n",
    "from os.path import join, exists, dirname\n",
    "from distributed.utils import TimeoutError as DistributedTimeoutError\n",
    "from distributed.client import wait, FIRST_COMPLETED, Future\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edc898-d339-40bc-8767-1e77fca78f71",
   "metadata": {},
   "source": [
    "# 2. Single-Node Model-Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe018bc9-abe6-4b1f-924e-4ff3cd951b7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Das einfachste wäre, wenn lokal mehrere GPUs verfügbar sind (dann können die Layers auch mit einer Pipeline kombiniert werden). PyTorch kümmert sich dann um die Kommunikation. \n",
    "\n",
    "Die Layers des Models (oder Teilnetzwerke) werden mit `.to('cuda:0')` auf die GPU platziert.\n",
    "\n",
    "Bei mehreren lokalen GPUs kann eine Pipeline erstellt werden, um das Training zu beschleinigen. Das klappt derzeit <u>nur lokal</u> auf Maschinen. <br>\n",
    "\n",
    "Pipeline-Parallelism unter PyTorch wird in Zukunft Inter-Node fähig sein.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "SINGLE-MACHINE MODEL PARALLEL BEST PRACTICES: https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html <br>\n",
    "Speed Up by Pipelining Inputs: https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html#speed-up-by-pipelining-inputs <br>\n",
    "PIPELINE PARALLELISM: https://pytorch.org/docs/stable/pipeline.html\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42191542-5e4b-4a41-9ef0-e43807377fa9",
   "metadata": {},
   "source": [
    "# -- Model-Parallel Single-Maschine -- #\n",
    "# Beispiel aus: https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html#basic-usage\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')            # Teil 1 auf GPU 0\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')             # Teil 2 auf GPU 1,     weitere auf GPU 2, 3, ... \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to('cuda:0')))                    # Hier muss der Output an den nächsten Teil weitergegeben werden.\n",
    "        return self.net2(x.to('cuda:1'))                            \n",
    ".... \n",
    "\n",
    "model = ToyModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(torch.randn(20, 10))\n",
    "labels = torch.randn(20, 5).to('cuda:1')                             # Die Labels müssen auf der GPU sein, wo die Outputs sind. \n",
    "loss_fn(outputs, labels).backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b586b-75ed-491e-a177-121a4d4aa140",
   "metadata": {},
   "source": [
    "# 3. Multi-Node Model-Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d6be4-3e72-4d03-908a-141e13ef8294",
   "metadata": {},
   "source": [
    "Hier sieht das Vorgehen ganz anders aus. Hier wird MNSG hauptsächlich betrachtet. \n",
    "\n",
    "Das Model kann vertikal aufgeteilt werden. Wenn jede Node mehrere GPUs hat, kann man dazu zusätzlich noch PyTorch DDP nutzen, um die gesamten Trainingsdaten auf Nodes aufzuteilen und so das Trainings zu beschleunigen. Das geht nur wenn das Model auf die lokalen GPUs aufgeteilt werden kann. das Aufteilen funktioniert dann wie bei Single-Node Model-Paralell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563ed85-a506-4b56-a109-d100329af2a3",
   "metadata": {},
   "source": [
    "## 3.1. Vorgehen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39eb58-32d6-4c64-a2e2-be058878af39",
   "metadata": {},
   "source": [
    "Hier wird Stückweise das vorgehen erklärt. Wir befinden uns im MNSG Bereich. Das Nertwerk wird in Teilnetze geschnitten, vertikal. Jede GPU eines Workers bekommt einen Teil.\n",
    "\n",
    "\n",
    "\n",
    "<u>Hinweis:</u><br>\n",
    "Wenn beim Programmieren Fehler passieren, können die Fehlermeldungen nicht sehr aussagekräftig sein, was die Fehlersuche erschwert.<br>\n",
    "Es kann vorkommen, dass nur folgendes ausgegeben wird: `terminate called without an active exception` oder `Shutdown RPC`. <br> \n",
    "Was und wo der Fehler war, wird nicht mitgeteilt.\n",
    "\n",
    "Wenn es hängt oder bei Problemen: Worker/Notebook/Cluster, ... neustarten.<br>\n",
    "Das kann manchmal helfen. Das Problem kann auftauchen, wenn Exceptions vorkommen. <br>\n",
    "Es kann sein das RPC Probleme macht, wenn direkt das Training neugestartet wird, dann müssen die Worker neugestartet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c03a7-652f-4b8d-9805-ce9f8d30d588",
   "metadata": {},
   "source": [
    "Die zwei unteren Abbildungen illustrieren das Prinzip. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f0c55-93a7-45c4-b580-4d2a4e506071",
   "metadata": {},
   "source": [
    "<p>\n",
    "<img src=\"./pictures/ptmp_rpc3.PNG\" width=\"565px;\" hight=\"465px;\" >\n",
    "<img src=\"./pictures/ptmp_rpc4.PNG\" width=\"265px;\" hight=\"165px;\" >\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18bcf5-fe4e-4d1b-9b7c-625461fce2fd",
   "metadata": {},
   "source": [
    "Es wird ein Worker ausgewählt, welcher die Trainingsfunktion ausführen soll. Die Restlichen stehen nur zur Verfügung und führen auf Anfragen, Funktionen und Klassen aus.\n",
    "\n",
    "Das ganze Netzwerk wird in Teilnetze zerteilt. Teil 1 des Netzes kann lokal oder auf einem anderen Worker liegen. Wenn lokal- wird das Ergebnis als RRef an W1 weitergegeben. <br>\n",
    "W1 macht dann an der Stelle weiter und liefert ein RRef zurück an W0. W0 gibt das RRef an W2, damit dieser sich mit der Referenz die Daten aus W1 holt. Am Ende <br> \n",
    "holt sich W0 das Endergebnis. \n",
    "\n",
    "Die RPC-Namen werden immer hochgezählt. Ein Worker mit Rang 3 bekommt den Namen w3.\n",
    "\n",
    "\n",
    "Es gibt noch die Möglichkeit bei der `forward()` Methode die Batches zu spliten. Dafür muss am Ende ein Future von PyTorch zurückgegeben werden. <br>\n",
    "Ein Beispiel der Anwendung ist unten verlinkt. Hier wird es nicht gezeigt.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Step 2: Stitch ResNet50 Model Shards Into One Module (Zeigt Batch-Splitting): https://pytorch.org/tutorials/intermediate/dist_pipeline_parallel_tutorial.html#step-2-stitch-resnet50-model-shards-into-one-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73fde2e0-1844-45ea-aee5-1e529683ef76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### Untere 2 Zellen werden als Module bald verfügbar sein #######\n",
    "#\n",
    "# Im Dispatcher unter  \"if rank_int==1:  # 1\" wird der Rang 1 für die Ausführung der Trainingsfunktion ausgewählt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "76e348f7-b43d-4b0f-ab88-8230fb564185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dask-Pytorch Dispatcher\n",
    "# Open Source Project: https://github.com/saturncloud/dask-pytorch-ddp\n",
    "###########################################################################\n",
    "\n",
    "#### Das hier nutzen\n",
    "\n",
    "import os\n",
    "from typing import List, Callable, Any, Dict\n",
    "from dask.distributed import Client\n",
    "import torch.distributed as dist\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def _get_worker_info(client: Client) -> List[Dict]:\n",
    "\n",
    "    workers = client.scheduler_info()[\"workers\"]\n",
    "    worker_keys = sorted(workers.keys())\n",
    "    workers_by_host: Dict[str, List[str]] = {}\n",
    "    for key in worker_keys:\n",
    "        worker = workers[key]\n",
    "        host = worker[\"host\"]\n",
    "        workers_by_host.setdefault(host, []).append(key)\n",
    "    host = workers[worker_keys[0]][\"host\"]\n",
    "    all_workers = []\n",
    "    global_rank = 0\n",
    "    for host in sorted(workers_by_host.keys()):\n",
    "        local_rank = 0\n",
    "        for worker in workers_by_host[host]:\n",
    "            all_workers.append(\n",
    "                dict(\n",
    "                    worker=worker,\n",
    "                    local_rank=local_rank,\n",
    "                    global_rank=global_rank,\n",
    "                    host=host,\n",
    "                )\n",
    "            )\n",
    "            local_rank += 1\n",
    "            global_rank += 1\n",
    "    return all_workers\n",
    "\n",
    "\n",
    "def run(\n",
    "    client: Client,\n",
    "    pytorch_function: Callable,\n",
    "    *args,\n",
    "    backend: str = \"nccl\",  # nccl | gloo\n",
    "    pass_local_rank: bool = False,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Dispatch a pytorch function over a dask cluster, and returns a list of futures\n",
    "    for the resulting tasks\n",
    "    \"\"\"\n",
    "    all_workers = _get_worker_info(client)\n",
    "    world_size = len(all_workers)\n",
    "    port = 23456  # pick a free port?\n",
    "    host = all_workers[0][\"host\"]\n",
    "    futures = []\n",
    "    for worker in all_workers:\n",
    "        if pass_local_rank:\n",
    "            fut = client.submit(\n",
    "                dispatch_with_ddp,\n",
    "                pytorch_function=pytorch_function,\n",
    "                master_addr=host,\n",
    "                master_port=port,\n",
    "                rank=worker[\"global_rank\"],\n",
    "                world_size=world_size,\n",
    "                *args,\n",
    "                local_rank=worker[\"local_rank\"],\n",
    "                backend=backend,\n",
    "                workers=[worker[\"worker\"]],\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            fut = client.submit(\n",
    "                dispatch_with_ddp,\n",
    "                pytorch_function=pytorch_function,\n",
    "                master_addr=host,\n",
    "                master_port=port,\n",
    "                rank=worker[\"global_rank\"],\n",
    "                world_size=world_size,\n",
    "                *args,\n",
    "                backend=backend,\n",
    "                workers=[worker[\"worker\"]],\n",
    "                **kwargs\n",
    "            )\n",
    "        futures.append(fut)\n",
    "    return futures\n",
    "\n",
    "\n",
    "# pylint: disable=too-many-arguments\n",
    "def dispatch_with_ddp(\n",
    "    pytorch_function: Callable,\n",
    "    master_addr: Any,\n",
    "    master_port: Any,\n",
    "    rank: Any,\n",
    "    world_size: Any,\n",
    "    *args,\n",
    "    backend: str = \"nccl\",\n",
    "    **kwargs\n",
    ") -> Any:\n",
    "    \n",
    "\n",
    "    # These are the parameters used to initialize the process group\n",
    "    master_addr = str(master_addr)\n",
    "    master_port = str(master_port)\n",
    "    rank_int = rank\n",
    "    world_size_int = world_size\n",
    "    rank = str(rank)\n",
    "    world_size = str(world_size)\n",
    "    \n",
    "    \n",
    "    os.environ[\"MASTER_ADDR\"] = master_addr\n",
    "    os.environ[\"MASTER_PORT\"] = master_port\n",
    "    os.environ[\"RANK\"] = rank\n",
    "    os.environ[\"WORLD_SIZE\"] = world_size\n",
    "    \n",
    "    os.environ[\"GLOO_SOCKET_IFNAME\"] = \"eno1\"  # unable to find Adress for eno4   etho zb, Netzwerkadresse\n",
    "    #os.environ[\"NCCL_SOCKET_IFNAME\"] = \"eno1\" \n",
    "    # Lösung: https://github.com/pytorch/tensorpipe/issues/201\n",
    "    os.environ[\"TP_SOCKET_IFNAME\"] = \"eno1\"\n",
    "    # https://discuss.pytorch.org/t/strange-behaviour-of-gloo-tcp-transport/66651/4\n",
    "    \n",
    "    ## Mappe GPU:0 zu allen anderen GPUs im Cluster. \n",
    "    #  - Alle Worker beginnen mit w, gefolgt von dem Rank\n",
    "    #  # Siehe https://pytorch.org/docs/stable/rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.set_device_map\n",
    "    # -- Für CPU:\n",
    "    #   - Kommentiere gpu-map unten bei der init_method. \n",
    "    gpu_map = {}\n",
    "    for i in range(world_size_int):\n",
    "        gpu_map[f'w{i}'] = {0: 0}\n",
    "    del gpu_map[f'w{rank_int}']    # Lösche eigenen Eintrag \n",
    "    print(f\"Rank: {rank_int} gpu_map: {gpu_map}\")\n",
    "    ## RPC Backend Optionen\n",
    "    options=rpc.TensorPipeRpcBackendOptions(\n",
    "        num_worker_threads=18, #128\n",
    "        rpc_timeout=60,\n",
    "        init_method=f'tcp://{master_addr}:{master_port}', device_maps=gpu_map  )\n",
    "    \n",
    "   \n",
    "    \n",
    "    available_rpc_worker = []\n",
    "    for i in range(world_size_int):\n",
    "             available_rpc_worker.append(f\"w{i}\")\n",
    "   \n",
    "    val=100\n",
    "    try: \n",
    "        \n",
    "        if rank_int == 1:  # 1\n",
    "        \n",
    "            rpc.init_rpc(f\"w{rank_int}\", rank=rank_int, world_size=world_size_int, rpc_backend_options=options, backend=rpc.BackendType.TENSORPIPE)            \n",
    "            print(f\"Init master, rank: {rank_int}\") \n",
    "            \n",
    "            json_dumps_str= json.dumps(available_rpc_worker)\n",
    "            os.environ[\"RPC_WORKER_LIST\"] = json_dumps_str\n",
    "            os.environ[\"RPC_WORKER_NAME\"] = f\"w{rank_int}\"\n",
    "            val = pytorch_function(*args, **kwargs)\n",
    "     \n",
    "        else:\n",
    "            \n",
    "            print(f\"init worker, rank: {rank_int}, RPC name: w{rank_int}\")\n",
    "            os.environ[\"RPC_WORKER_NAME\"] = f\"w{rank_int}\"\n",
    "            rpc.init_rpc(f\"w{rank_int}\", rank=rank_int, world_size=world_size_int, rpc_backend_options=options, backend=rpc.BackendType.TENSORPIPE) \n",
    "                        \n",
    "    finally:\n",
    "        rpc.shutdown()\n",
    "        print(\"Shutdown RPC\")\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bd1977ee-03ca-475b-89a8-75d6b6424662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from distributed.pubsub import Pub, Sub\n",
    "from typing import List, Optional, Dict\n",
    "from distributed.client import wait, FIRST_COMPLETED, Future\n",
    "from os.path import join, exists, dirname\n",
    "from distributed.utils import TimeoutError as DistributedTimeoutError\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from torch.distributed.rpc import init_rpc, rpc_async, rpc_sync, remote\n",
    "import torch.distributed.rpc as rpc\n",
    "\n",
    "\n",
    "# Dask-Pytorch Dispatcher\n",
    "# Open Source Project: https://github.com/saturncloud/dask-pytorch-ddp\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "from typing import List, Callable, Any, Dict\n",
    "\n",
    "class DaskResultHandler:\n",
    "    \"\"\"\n",
    "    This class use Dask pubsub infra to pass intermediate results back from PyTorch\n",
    "    jobs to the client.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pub_sub_key:str=\"my_channel\", trainingpath:str=\"template_pytorch/\"):\n",
    "        \"\"\"Init Class\n",
    "        Hier kann man zu Beginn Ordner oder Pfade festlegen.\n",
    "        Ein Pfad, den man übergeben will, sollte so aussehen: \"training/ordner1/ordner2/\"\n",
    "        \n",
    "        Wenn nötig, können auch Funktionen ausgeführt werden, um Pfade, etc. zu erstellen. \n",
    "        \n",
    "        trainingpath: Wo das Model gespeichert wird. \n",
    "        pub_sub_key:  Publisher/Subscriber Channel Name.\n",
    "        _setup_working_dir: Erstellt den Ordner \"training\", wenn nicht vorhanden\n",
    "        \"\"\"\n",
    "        \n",
    "        self.training_path = trainingpath\n",
    "        self.pub_sub_key   = pub_sub_key\n",
    "        #self._setup_working_dir(trainingpath)\n",
    "        \n",
    "        # Erstelle Pfade, sonstige Vorbereitungen... \n",
    "        # _setup_working_dir()\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def _get_all(cls, sub: Sub):\n",
    "        \"\"\"Auslesen des Channels:\n",
    "        Geben die Daten zurück die jede Epoche von einem Worker hochgeladen werden. \n",
    "        - Host ist meist Subscriber und hört allen Topics zu.\n",
    "        - Es kann mehrere Nachrichten und Channels geben.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                yield sub.get(timeout=1.0)\n",
    "            except DistributedTimeoutError:\n",
    "                break\n",
    "                \n",
    "\n",
    "    def _get_results(self, futures: List[Future], raise_errors: bool = True):\n",
    "        \"\"\"Get Dask results.\n",
    "        Hier erstellen wir ein Subscriber sub_stats, der die Daten aus dem Channel pub_sub_key auslesen soll. \n",
    "        \n",
    "        \"\"\"    \n",
    "        sub_stats = Sub(self.pub_sub_key)  \n",
    "\n",
    "        \n",
    "        while True: \n",
    "            \n",
    "            # Für Subscriber, get Channel data.\n",
    "            for obj in self._get_all(sub_stats):     \n",
    "                yield obj\n",
    "            \n",
    "            # keine Futures? => break. \n",
    "            if not futures:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                # Dask:   wait(fs[, timeout, return_when])      Wait until all/any futures are finished\n",
    "                # Read here: https://distributed.dask.org/en/stable/api.html\n",
    "                result = wait(futures, 5, FIRST_COMPLETED)  #0.1\n",
    "            except DistributedTimeoutError:\n",
    "                continue\n",
    "\n",
    "            for fut in result.done:     \n",
    "                try:                   \n",
    "                    fut.result()  \n",
    "                    \n",
    "                except Exception as e:  # pylint: disable=broad-except\n",
    "                    logging.exception(e)\n",
    "                    \n",
    "                    if raise_errors:\n",
    "                        raise\n",
    "                        \n",
    "            futures = result.not_done\n",
    "\n",
    "\n",
    "    def process_results(self, futures: List[Future], raise_errors: bool = True) -> None:\n",
    "        \n",
    "        \"\"\"Verarbeitung der Daten der Futures die von Dask geliefert werden.\n",
    "        Die Ergebnisse kommen als Liste an.\n",
    "        \n",
    "        Die Liste \"futures\" enthält alles, was wir mit dem Publisher hochladen.\n",
    "        Das kann das Model sein (als Dict) und weitere Werte wie Loss, Acc, ...\n",
    "        \n",
    "        Hier kann eine Bedingung eingefügt werden, um das Training zu stoppen und das Model zu speichern. \n",
    "        \n",
    "        Mit torch.save wird das Model gespeichert. Oder implementiere eine eigene Methode für das Speichern. \n",
    "        \"\"\"\n",
    "\n",
    "        for result in self._get_results(futures, raise_errors=raise_errors):\n",
    "            \n",
    "            \n",
    "            \n",
    "            if \"msg\" in result:\n",
    "                msg = result['msg']\n",
    "                print(msg)\n",
    "            \n",
    "            if \"model_dict\" in result:\n",
    "                model_dict_data = result['model_dict']\n",
    "                \n",
    "                print(\"saving...\")\n",
    "                \n",
    "                path   = model_dict_data['path']\n",
    "                kwargs = model_dict_data['kwargs']\n",
    "                \n",
    "                \n",
    "                if len(kwargs.keys()) !=0 :   # Checkpoint\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model_dict_data['model_state_dict'],\n",
    "                        'kwargs':           kwargs\n",
    "                         }, str(path+\".ckpt\"))\n",
    "                        \n",
    "                else:                         # .pt oder .pth \n",
    "                    print(f\"Saving Model to {path}\")\n",
    "                    torch.save(model_dict_data['model_state_dict'], str(path+\".pt\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a765a18-1bb2-4ede-a85e-231d942b8806",
   "metadata": {},
   "source": [
    "## 3.2 Das Netz aufteilen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02062e-2645-454e-9dab-062d5c55038a",
   "metadata": {},
   "source": [
    "Jetzt wird ein Netzwerk vertikal aufgeteilt. Als Beispiel nehmen wir AlexNet, das Bilder klassifizieren soll. <br>\n",
    "Mit 3 Nodes (eine GPU per Node) kann das Model in 3 Stücke zerteilt werden. \n",
    "\n",
    "Wie die Aufteilung gemacht wird, kann die Trainingszeit beeinflussen. \n",
    "\n",
    "Teilnetzwerke können die Layers in eine Pipeline stecken.\n",
    "\n",
    "So sieht das ganze Netzwerk aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1777a7c4-5b3c-46dc-bb6d-719c5d8b4fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AlexNet: https://blog.paperspace.com/alexnet-pytorch/\n",
    "\n",
    "# - Klassen: 10 \n",
    "# Unser AlexNet.:\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))  # Output geht zu Teil 2\n",
    "        #----------------------------------------------------------------------------- Schnitt, Netz Teil 1\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2)) # Output geht zu Teil 3\n",
    "        #----------------------------------------------------------------------------- Schnitt, Netz Teil 2\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        #----------------------------------------------------------------------------- Rest: Netz Teil 3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        #-------------------------\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #-------------------------\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "        #-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df073c-2109-4d9a-8ae5-be279a043f49",
   "metadata": {},
   "source": [
    "Damit PyTorch RPC funktioniert, müssen die Teilnetzwerke in einer Datei stehen, die jeder Worker dann bekommt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93d682-82b2-4efb-b5cb-8886f4d5c72b",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/ptmp_rpc5.PNG\" width=\"765px;\" hight=\"565px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a067d-192b-442e-999e-2685b18d7b3b",
   "metadata": {},
   "source": [
    "In Jupyter kann mit der Magic `%%writefile pytorch_AlexNetMP.py` eine Datei geschrieben werden.\n",
    "\n",
    "In dieser Datei wird das Netzwerk aufgeteilt. Die Details werden unten besprochen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0cf2f372-d86b-4961-aa0a-c7ecc1afd2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pytorch_AlexNetMP.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pytorch_AlexNetMP.py\n",
    "\n",
    "\n",
    "\"\"\" Hilfsmethoden \"\"\"\n",
    "#### -------------------------------------------- ####\n",
    "def _call_method(method, rref, *args, **kwargs):\n",
    "    return method(rref.local_value(), *args, **kwargs)  #rref.local_value()\n",
    "\n",
    "def _remote_method(method, rref, *args, **kwargs):\n",
    "    return rpc.rpc_sync(\n",
    "        rref.owner(),\n",
    "        _call_method,\n",
    "        args=[method, rref] + list(args),\n",
    "        kwargs=kwargs\n",
    "    )\n",
    "\n",
    "def _parameter_rrefs(module):\n",
    "    param_rrefs = []\n",
    "    for param in module.parameters():\n",
    "        param_rrefs.append(RRef(param))\n",
    "    return param_rrefs\n",
    "#### -------------------------------------------- ####\n",
    "\n",
    "\n",
    "\n",
    "## Importiere alles was für die Netzwerke und etc. gebraucht wird. \n",
    "#  PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "#  Für PyTorch RPC \n",
    "from torch.distributed.rpc import RRef, init_rpc, rpc_async, rpc_sync, remote\n",
    "import torch.distributed.rpc as rpc\n",
    "import threading\n",
    "\n",
    "##################################### Teile auf. #####################################\n",
    "\n",
    "\n",
    "## -- Teil 1 -- ##\n",
    "# Teil 1 soll lokal sein.\n",
    "#   ** Kann Remote zu sich selber sein.\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(0)  # Wähle Device  GPP / CPU\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2)).to(self.device)   # Layers werden Explizit auf GPU gepackt, bei CPU gff. nicht erforderlich.\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2)).to(self.device)\n",
    "        \n",
    "        # Das wird hinzugefügt.\n",
    "        self._lock = threading.Lock()     \n",
    "        \n",
    "        \n",
    "        self.savename=\"net1\"   # Name des Netzes das beim Speichern gesetzt wird. \n",
    "         \n",
    "    def forward(self, x):\n",
    "        with self._lock:\n",
    "            out = self.layer1(x)\n",
    "            out = self.layer2(out)\n",
    "        return out.cuda()     # Durch die GPU-Map müssen die Daten nicht vorher auf die CPU geschoben werden, das spart zeit.\n",
    "                              # - Ohne GPU:  nur out oder out.cpu()\n",
    "    \n",
    "    # Parameter werden als RRef zurückgegeben.\n",
    "    def parameter_rref(self):\n",
    "        return [RRef(p) for p in self.parameters()]\n",
    "    \n",
    "    # Speichern und Laden des Models #\n",
    "    def save_local(self, path=\"./\"):\n",
    "        print(f\"net1 save: {str(path+self.savename+'.pt')}\")\n",
    "        torch.save(self.state_dict(), str(path+self.savename+\".pt\") )\n",
    "    \n",
    "    def load_local(self, path=\"./\"):\n",
    "        print(f\"net1 load from {str(path+self.savename+'.pt')}\")\n",
    "        self.load_state_dict(torch.load(str(path+self.savename+\".pt\")))\n",
    "    \n",
    "\n",
    "\n",
    "## -- Teil 2 -- ##\n",
    "# Teil 2 ist Remote und nicht lokal wie Teil 1.\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net2, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(0)\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU()).to(self.device)\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU()).to(self.device)\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2)).to(self.device)\n",
    "        \n",
    "        # Das wird hinzugefügt.\n",
    "        self._lock = threading.Lock() \n",
    "        \n",
    "        self.savename=\"net2\"\n",
    "      \n",
    "    \n",
    "    def forward(self, x_rref): # RRef #  \n",
    "        x = x_rref.to_here().to(self.device)   # Neu: Netz 2 bekommt RRef vom Ergebnis, holt sich die Kopie vom Besitzer des RRefs \n",
    "        with self._lock:       \n",
    "            out = self.layer3(x)\n",
    "            out = self.layer4(out)\n",
    "            out = self.layer5(out)\n",
    "            out = out.reshape(out.size(0), -1)\n",
    "        return out.cuda()  \n",
    "\n",
    "    \n",
    "    # Parameter werden als RRef zurückgegeben.\n",
    "    def parameter_rref(self):\n",
    "        return [RRef(p) for p in self.parameters()]\n",
    "    \n",
    "    \n",
    "    def get_model_state_dict(self):\n",
    "        return self.state_dict()\n",
    "    \n",
    "        \n",
    "    def save_local(self, path=\"./\"):\n",
    "        print(f\"net2 save: {str(path+self.savename+'.pt')}\")\n",
    "        torch.save(self.state_dict(), str(path+self.savename+\".pt\") )\n",
    "    \n",
    "    def load_local(self, path=\"./\"):\n",
    "        print(f\"net2 load from {str(path+self.savename+'.pt')}\")\n",
    "        self.load_state_dict(torch.load(str(path+self.savename+\".pt\")))\n",
    "    \n",
    "    \n",
    "    \n",
    "## -- Teil 3 -- ##\n",
    "\n",
    "# - Selbes vorgehen. Bei anderen Netzen genau so. \n",
    "class Net3(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net3, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(0)\n",
    "       \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU()).to(self.device)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU()).to(self.device)\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes)).to(self.device)\n",
    "        \n",
    "        # Das wird hinzugefügt.\n",
    "        self._lock = threading.Lock()\n",
    "        \n",
    "        self.savename=\"net3\"\n",
    "            \n",
    "        \n",
    "    def forward(self, x_rref): # RRef #\n",
    "        x = x_rref.to_here().to(self.device) # Neu: Netz 3 bekommt RRef vom Ergebnis, holt sich die Kopie vom Besitzer des RRefs \n",
    "        with self._lock:\n",
    "            out = self.fc(x)\n",
    "            out = self.fc1(out)\n",
    "            out = self.fc2(out)\n",
    "                \n",
    "        return out.cuda()\n",
    "    \n",
    "    # Parameter werden als RRef zurückgegeben.\n",
    "    def parameter_rref(self):\n",
    "        return [RRef(p) for p in self.parameters()]\n",
    "    \n",
    "    def save_local(self, path=\"./\"):\n",
    "        print(f\"net3 save: {str(path+self.savename+'.pt')}\")\n",
    "        torch.save(self.state_dict(), str(path+self.savename+\".pt\") )\n",
    "    \n",
    "    def load_local(self, path=\"./\"):\n",
    "        print(f\"net3 load from {str(path+self.savename+'.pt')}\")\n",
    "        self.load_state_dict(torch.load(str(path+self.savename+\".pt\")))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "## --- Führe alles zusammen. --- ##\n",
    "#\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.device = torch.device(0)\n",
    "\n",
    "        # Lokal\n",
    "        self.part1 = Net1().to(self.device)  # Lokal     w1\n",
    "        # Node w1 führt Trainingsfunktion aus\n",
    "        self.part2 = rpc.remote(\"w0\", Net2)  # Remote    w0\n",
    "        self.part3 = rpc.remote(\"w2\", Net3)  # Remote    w2\n",
    "        \n",
    "    def forward(self, x):\n",
    "         \n",
    "        x_rref1 = RRef(self.part1.forward(x))                 # Ergebnis zu RRef, damit die Referenz an Part2(Netz2) gesendet werden kann.\n",
    "        x_rref2 = self.part2.remote().forward( x_rref1 )      # RRef des Ergebnisses wird zurück gegeben. Diese soll weitergereicht werden.\n",
    "        # Bei weiteren:  x_rref n = self.part n.remote().forward( x_rref n-1 ), Es sollte immer eine Referenz zurückgegeben werden.\n",
    "        data1   = self.part3.rpc_sync().forward( x_rref2 )    # data1 ist ein Tensor. (Für das Batch-Splitting muss es ein Future von PyTorch sein)\n",
    "        return data1  # ist Tensor\n",
    "        \n",
    "    # Methode erweitert Liste um Parameter. \n",
    "    def parameter_rrefs(self):\n",
    "        remote_params = []\n",
    "        # create RRefs for local parameters\n",
    "        remote_params.extend(_parameter_rrefs(self.part1))\n",
    "        # get RRefs remote\n",
    "        remote_params.extend(self.part2.remote().parameter_rref().to_here())\n",
    "        remote_params.extend(self.part3.remote().parameter_rref().to_here())\n",
    "\n",
    "        return remote_params\n",
    "    \n",
    "    \n",
    "    \"\"\"Speichern und Laden der Modelle.\n",
    "    - Die Teilmodelle werden dort gespeichert, wo sie ausgeführt werden.\n",
    "      So werden diese auch geladen.\n",
    "    \"\"\"\n",
    "        \n",
    "    def saveModelShardsLokalOnWorker(self, path:str=\"./\"):\n",
    "        self.part1.save_local(path)\n",
    "        \n",
    "        self.part2.remote().save_local(path)\n",
    "        self.part3.remote().save_local(path)\n",
    "        \n",
    "    def loadModelShardsLokalOnWorker(self, path:str=\"./\"):\n",
    "        self.part1.load_local(path)\n",
    "        \n",
    "        self.part2.remote().load_local(path)\n",
    "        self.part3.remote().load_local(path)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "######### Datei: writefile pytorch_AlexNetMP.py"
   ]
  },
  {
   "cell_type": "raw",
   "id": "243f81d0-44ea-4c3e-9422-fc313ce63ec3",
   "metadata": {},
   "source": [
    "# -- Methode gibt Parameter als RRef zurück. -- #                                     # -- Device und forward() -- #\n",
    "def parameter_rref(self):                                                               self.device = torch.device(0) # Setze device, um Layers darauf zu packen.                        \n",
    "    return [RRef(p) for p in self.parameters()]                                         self._lock = threading.Lock() # Verhindert weiteren Zugriff \n",
    "                                             \n",
    "# -- Methode gibt alle Paramater aller Teilnetze -- #                                   Wenn das Teilnetz lokal ist, muss bei forward() kein RRef übergeben werden (siehe Netz1)\n",
    "# Das wird für den DistributedOptimizer gebraucht, der RRefs nimmt.                     Bei Netz2, forward(self, x_rref), wird das Ergebnis von Netz1 als Referenz an Netz2 übergeben.\n",
    "def parameter_rrefs(self):                                                              - Mit \"x = x_rref.to_here().to(self.device)\" Lädt Netz2 die Daten von dem das RRef gehört. \n",
    "    remote_params = []\n",
    "     # create RRefs for local parameters\n",
    "    remote_params.extend(_parameter_rrefs(self.part1))\n",
    "    # get RRefs remote\n",
    "    remote_params.extend(self.part2.remote().parameter_rref().to_here())\n",
    "    remote_params.extend(self.part3.remote().parameter_rref().to_here())\n",
    "\n",
    "    return remote_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52621788-8370-486f-b8fb-b032f66825ca",
   "metadata": {},
   "source": [
    "Dann muss die Datei mit dem Cluster geteilt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7439b6e8-0333-4d8b-9170-a7683a476df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upload_file('pytorch_AlexNetMP.py')\n",
    "import pytorch_AlexNetMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c06fc-cec9-4d91-ad6a-720b7b5224c9",
   "metadata": {},
   "source": [
    "<u>Hinweis zum Dataloader:</u><br>\n",
    "Um die Parameter num_workers und prefetch_factor zu nutzen, muss unter Dask eingestellt werden, dass die Worker nicht als Daemon Prozesse starten. Diese Parameter können die Trainingszeit verkürzen. <br>\n",
    "`num_workers:int` Erstelle n-Prozesse zum laden der Daten. <br>\n",
    "`prefetch_factor:int` Lade n-Batches vor. \n",
    "\n",
    "Damit das funktioniert, muss <u>vor</u> dem start der Worker eine Umgebungsvariable gesetzt werden. Bei jedem Worker muss es gesetzt sein. <br>\n",
    "Setze: `DASK_DISTRIBUTED__WORKER__DAEMON=False`. Der Standartwert ist `True`.\n",
    "\n",
    "\n",
    "Eine Abfrage kann so gemacht werden:<br>\n",
    "`dask.config.get(\"distributed.worker.daemon\")`. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Setzen und abfragen von Einstellungen in Dask: https://docs.dask.org/en/latest/configuration.html#conversion-utility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1321c-7478-4068-b3df-96d50c02dfe7",
   "metadata": {},
   "source": [
    "Um eine andere Sicht auf die Funktionsweise zu bekommen, wird eine kleine Funktion im RPC-Kontext ausgeführt.  <br>\n",
    "Um auszuwählen welcher Worker die Funktion ausführen soll: Im Dispatcher => `if rank_int==1:  # 1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "67c70e4c-d334-4eb5-97f5-eab3149f2afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_file.py\n",
    "import time\n",
    "\n",
    "# Klassen und Funktionen... \n",
    "def add(a,b):\n",
    "    return a+b\n",
    "\n",
    "def mul(a,b):\n",
    "    return a*b\n",
    "\n",
    "def dev(a,b):\n",
    "    time.sleep(10)\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ac7b69f2-1822-4d40-bcfa-78da71551623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.upload_file('my_file.py')\n",
    "import my_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f4d6c-de04-4dc7-8cbb-beab97757f12",
   "metadata": {},
   "source": [
    "Beachte, wenn hier ein Fehler auftaucht, kann es sein, dass es keine klare Fehlermeldung gibt. <br>\n",
    "Z.B. wenn `print()` groß geschrieben wird: `Print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fe578ce2-9c7b-4fde-a70b-84bc2ea5812b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Kontext: RPC und RRef\n",
    "def my_rpc_function():\n",
    "    pub_stats  = Pub(\"my_channel\")                     \n",
    "    rpc_worker_name = os.getenv('RPC_WORKER_NAME') \n",
    "    rpc_worker_list = os.getenv('RPC_WORKER_LIST')\n",
    "    \n",
    "    msg = f\"Hallo, I'm the RPC-Worker {rpc_worker_name}\"\n",
    "    print(msg)                  # Konsole\n",
    "    pub_stats.put({'msg': msg}) # Jupyter \n",
    "    \n",
    "    msg = f\"RPC-Worker List: {rpc_worker_list}\"\n",
    "    pub_stats.put({'msg': msg}) # Jupyter \n",
    "    \n",
    "    rref_1 = rpc.remote(\"w2\", my_file.add, args=(3, 3,)) # Nur ein \"Pointer\"\n",
    "    msg = f\"\\nrref_1 ist: {rref_1} \\nHole Ergebnis, jetzt: {rref_1.to_here()}\"\n",
    "    del rref_1\n",
    "    pub_stats.put({'msg': msg}) \n",
    "    \n",
    "\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "356d1ba6-1b16-42ed-ba3c-12bf6f9f6dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 3\n",
      "Hallo, I'm the RPC-Worker w1\n",
      "RPC-Worker List: [\"w0\", \"w1\", \"w2\"]\n",
      "\n",
      "rref_1 ist: UserRRef(RRefId = GloballyUniqueId(created_on=1, local_id=0), ForkId = GloballyUniqueId(created_on=1, local_id=1)) \n",
      "Hole Ergebnis, jetzt: 6\n",
      "CPU times: user 22.5 ms, sys: 0 ns, total: 22.5 ms\n",
      "Wall time: 4.92 s\n"
     ]
    }
   ],
   "source": [
    "# Starte Training...\n",
    "# - Wird später als Modul verpackt. - #\n",
    "workers = client.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "print(f\"Worker: {n_workers}\")\n",
    "client.wait_for_workers(n_workers)\n",
    "rh = DaskResultHandler()\n",
    "time.sleep(1)\n",
    "futures = run(client, my_rpc_function)\n",
    "%time rh.process_results(futures, raise_errors=False)\n",
    "time.sleep(1)\n",
    "del rh, futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "227eaf88-6c4f-42a1-8287-46ea1fb40071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebedd8c-e6be-42a3-beee-31d2c3ecaf88",
   "metadata": {},
   "source": [
    "Jetzt zum Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d3444083-b006-4561-b5d4-c2ae85fb5fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Funktion im RPC-Kontext ##\n",
    "\n",
    "def train():\n",
    "    pub_stats  = Pub(\"my_channel\")            # Channel          \n",
    "    rpc_worker_name = os.getenv('RPC_WORKER_NAME') # RPC Name der bei der Initialisierung gesetzt wird.\n",
    "    device = torch.device(\"cuda\")  # 'cuda': Nutze alle GPUs | 0: nutze GPU 0 | 'cpu': Nutze CPU, Backend auf gloo stellen | \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    \"\"\"Edits: \n",
    "    num_epochs: Epochen\n",
    "    batch_size: Batchgröße \n",
    "      - Die Auswahl von batch_size kann die Trainingszeit und Genauigkeit beeinflussen.\n",
    "    transform: Transformiere Bilddaten\n",
    "    trainset: Erstellt ein PyTorch Dataset. \n",
    "      - Wie man eigene Datasets erstellt findet, man weiter unten.  \n",
    "    \"\"\"\n",
    "    \n",
    "    num_epochs = 5 # 5\n",
    "    batch_size = 128   \n",
    "    \"\"\" \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465],\n",
    "            std=[0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,  download=True, transform=transform)\n",
    "    # Beim Dataloader kann num_workers und prefetch_factor übergeben werden. In Dask bevor die Worker starten: export DASK_DISTRIBUTED__WORKER__DAEMON=False\n",
    "    loader = DataLoader(trainset, batch_size=batch_size, num_workers=2, prefetch_factor=2, pin_memory=True)  # num_workers=4, prefetch_factor=2,  pin_memory=True\n",
    "    \n",
    "    model = pytorch_AlexNetMP.AlexNet().to(device)   # Erstelle Model und setze auf GPU  \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Der DistributedOptimizer bekommt die Modelparameter als RRefs. \n",
    "    optimizer = DistributedOptimizer(\n",
    "        optim.SGD,               # Optimierer Klasse\n",
    "        model.parameter_rrefs(), # Parameter\n",
    "        lr=0.005,                # Rest sind **kwargs für optim.SGD\n",
    "        momentum=0.9,\n",
    "        weight_decay = 0.005    \n",
    "    )\n",
    "    \n",
    "    \n",
    "###########################################################################\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        correct = 0\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            \n",
    "            batch_x = batch_x.to(device) \n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            with dist_autograd.context() as context_id:   # Neu dazugekommen \n",
    "                \n",
    "                print(i)  # Um zu sehen, wie schnell die Batches durchgehen. \n",
    "                   \n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y) \n",
    "\n",
    "                dist_autograd.backward(context_id, [loss])  # Übergebe dist_autograd ID und loss.\n",
    "                optimizer.step(context_id)\n",
    "                 \n",
    "                ########## Evaluierung nach dem PyTorch Basic Tutorial\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "                if i % 100==0:\n",
    "                    print(\"Batch \", i)\n",
    "          \n",
    "                if torch.cuda.is_available():\n",
    "                         correct += (predicted.cpu() == torch.flatten(batch_y) .cpu()).sum()\n",
    "                else:\n",
    "                        orrect += (predicted == torch.flatten(batch_y) ).sum()\n",
    "                #########\n",
    "        \n",
    "        model.saveModelShardsLokalOnWorker()  # Speichere Model \n",
    "        accuracy = 100 * correct / len(trainset)\n",
    "           \n",
    "        # msg: Schreibe Nachricht die in Jupyter Ausgaben generiert.\n",
    "        msg=f\"Epoche: ({epoch+1}/{num_epochs}), loss: {loss.item()}, acc: {accuracy}\"\n",
    "        pub_stats.put({'msg': msg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54558640-799a-48e6-ab3c-f6e51c02c6dd",
   "metadata": {},
   "source": [
    "<b>*</b> Um das Training erneut durchzuführen, müssen die Worker ggf. neugestartet und die  .py Datei hochgeladen werden."
   ]
  },
  {
   "cell_type": "raw",
   "id": "38ec21e4-24dd-4011-a6d3-633b56299bdc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### -- pytorch_tools kann dafür noch nicht genutzt werden -- ###\n",
    "\n",
    "# Am Ende wird die Systemzeit ausgegeben. Die Stunden können abweichen. Mit date_time_hour_offset kann es angepasst werden. Rechne zur Uhrzeit +/- n-Stunden.\n",
    "# - pytorch_tools.run(train, client, date_time_hour_offset:int=0 )  Zeitformat:  Tag-Monat-Jahr  Stunde-Minute-Sekunde\n",
    "pytorch_tools.run(train, client, pytorch_mode=\"model_parallel\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "343b488b-4d00-4aad-8bc2-2a6cd8ac7134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 3\n"
     ]
    }
   ],
   "source": [
    "# Dask \n",
    "workers = client.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "print(f\"Worker: {n_workers}\")\n",
    "\n",
    "client.wait_for_workers(n_workers)\n",
    "\n",
    "rh = DaskResultHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e0ef154b-f359-44b3-96a4-f8f5b72d4839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoche: (1/5), loss: 1.1037698984146118, acc: 48.48400115966797\n",
      "Epoche: (2/5), loss: 0.9124933481216431, acc: 66.1500015258789\n",
      "Epoche: (3/5), loss: 0.7793256044387817, acc: 72.61599731445312\n",
      "Epoche: (4/5), loss: 0.6951331496238708, acc: 76.2699966430664\n",
      "Epoche: (5/5), loss: 0.5705133080482483, acc: 78.80400085449219\n",
      "CPU times: user 550 ms, sys: 85.6 ms, total: 636 ms\n",
      "Wall time: 18min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:29:10,096 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "ERROR:distributed.client:Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "futures = run(client, train)\n",
    "%time rh.process_results(futures, raise_errors=False)\n",
    "time.sleep(1)\n",
    "del rh, futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfca10-754b-4baf-96bd-53b09ebfbf69",
   "metadata": {
    "tags": []
   },
   "source": [
    "Diese Methoden zeigt, wie Aufteilung der Worker ist. Das wird für die Verteilung genutzt. <br>\n",
    "`pytorch_tools.listDaskWorker(client)` <br>\n",
    "\n",
    "\n",
    "global_rank 0 => RPC-Worker Name w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "de970b96-4db4-4061-8cc2-81f2f750f4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'worker': 'tcp://149.201.182.188:46051',\n",
       "  'local_rank': 0,\n",
       "  'global_rank': 0,\n",
       "  'host': '149.201.182.188'},\n",
       " {'worker': 'tcp://149.201.182.203:40883',\n",
       "  'local_rank': 0,\n",
       "  'global_rank': 1,\n",
       "  'host': '149.201.182.203'},\n",
       " {'worker': 'tcp://149.201.182.205:36163',\n",
       "  'local_rank': 0,\n",
       "  'global_rank': 2,\n",
       "  'host': '149.201.182.205'}]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aufteilung der Worker\n",
    "pytorch_tools.listDaskWorker(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2bb86-0afd-4801-82de-0800b4305faf",
   "metadata": {},
   "source": [
    "## 3.3 Evaluieren in der Trainingsloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125cfce-c0d5-4c8b-8624-f50ee1d776a2",
   "metadata": {},
   "source": [
    "Bei dem Trainieren kann man neben dem normalen Vorgehen auch das Model gleichzeitig evaluieren, dazu muss man auch einiges beachten. Eines der wichtigen Dinge ist, dass bestimmte Teile auf der GPU und andere auf der CPU sein müssen, damit das Evaluieren gut geht, sonst tauchen Fehler auf.\n",
    "\n",
    "Das folgende Beispiele zeigt eine Trainingsschleife, wo auch die Genauigkeit getestet wird. Aufkommende Fehlern weisen auf die Bereiche hin, es kann vorkommen das manche Fehlermeldungen nicht sehr aussagekräftig sind, meist findet man auf GitHub und andere Webseiten Lösungen dazu."
   ]
  },
  {
   "cell_type": "raw",
   "id": "08b3e284-eb89-42d1-8b7f-e6d3055b3028",
   "metadata": {},
   "source": [
    "# RNN |  dnn_RNN Notebook | https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/#3-building-a-recurrent-neural-network-with-pytorch-gpu\n",
    " accuracy=0\n",
    "        if  (worker_rank == 0):\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = images.view(-1, seq_dim, input_dim).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "# LSTM | dnn_1_lstm | https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/ \n",
    " if worker_rank == 0:\n",
    "\n",
    "            # Validation\n",
    "            if epoch % 100 != 0:\n",
    "                continue\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # tensor.detach().cpu().numpy()\n",
    "                y_pred = model(X_train)\n",
    "\n",
    "                tmp_data_rmse = criterion(y_pred, y_train)\n",
    "                tmp_data_rmse = tmp_data_rmse.cpu()                 # Move to CPU\n",
    "                train_rmse = np.sqrt(tmp_data_rmse)\n",
    "\n",
    "                y_pred = model(X_test)\n",
    "\n",
    "                tmp_data_rmse = criterion(y_pred, y_test) \n",
    "                tmp_data_rmse = tmp_data_rmse.cpu()                 # Move to CPU          \n",
    "\n",
    "                test_rmse = np.sqrt(tmp_data_rmse)                  # Für Ausgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf1293-ebca-41ce-8e1c-04dc1692992c",
   "metadata": {},
   "source": [
    "##  4. Details zu Datasets und Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11139ce4-4bcd-472b-9fb2-b2ce761d5a50",
   "metadata": {},
   "source": [
    "Das PyTorch Dataset ermöglicht das einfache Umgehen  mit den Daten. Die Funktion braucht 3 Methoden: `__init__`, `__len__` und `__getitem__`. In der init Methode kann man z.B. die Daten nochmal verändern oder von dort aus laden. \n",
    "\n",
    "Ohne ein Dataset können Daten so direkt geladen werden: `Train_loader = DataLoader(torch.utils.data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)`.<br>\n",
    "Es ist leicht und schnell erledigt. Man kann auch ein eigenes PyTorch Dataset erstellen. Beispiele dazu folgen.\n",
    "\n",
    "Der Dataloader wird beim Training genutzt und hat Zugriff auf das Dataset.\n",
    "\n",
    "Hier bei Model-Parallel, wird nur ein Worker die Daten für das Training liefern. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "PyTorch Dataset und Dataloader: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#loading-a-dataset  <br>\n",
    "PyTorch Dataloader https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954b475-8953-4085-bd4e-90f2ca3321bb",
   "metadata": {},
   "source": [
    "Das Laden und Verarbeiten der Daten kann als Funktion ausgelagert werden. <br>\n",
    "Ggf. müssen diese Funktionen auch als Datei hochgeladen werden.\n",
    "\n",
    "<u>Hinweis:</u><br>\n",
    "Wenn es zu einem Pickelerror kommt, müssen bestimmte Klassen und Funktionen in eine .py Datei geschrieben und von jedem Worker importiert werde. <br>\n",
    "Dateien können mit `client.upload_file('myfile.py')` hochgeladen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c91fb9-d2a8-4b9e-a93c-4d12bba5e203",
   "metadata": {},
   "source": [
    "## 4.1 Eigenes PyTorch Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b88832a-20fd-4ae4-a8dc-ad5731846cd0",
   "metadata": {},
   "source": [
    "# Eigenes Dataset was für das training genutzt wird.\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "       Lade Daten...\n",
    "       Worker mit Rang n und IP m soll diese Daten laden... \n",
    "       Einstellungen...\n",
    "    \n",
    "    def __len__(self):\n",
    "        Gebe Länge der Daten zurück\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Verändere Daten ggf. \n",
    "        # .... \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29db3a8-9d3d-4492-a299-8b44f54b0aec",
   "metadata": {},
   "source": [
    "Das Beispiel zeigt, wie man derzeit Bilddaten aus dem HDFs laden könnte (so ähnlich auch für lokale Daten). \n",
    "\n",
    "Als erstes listen wir alle Pfade auf, danach laden wir die Bilder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3837a2-3c6a-4fde-a51b-2ae4cdbdf103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste alle Pfade der Bilder auf.\n",
    "def get_filenames(fs): \n",
    "    \n",
    "    classes =['dog', 'chicken']   # Klassen dir wir haben (und auch verzeichnisse) \n",
    "    data = []\n",
    "    file_location = []\n",
    "    # HDFs verbindung\n",
    "    hdfs = fs.HadoopFileSystem(\"hdfs://sun.bigdata.fh-aachen.de\", port=9000, user=\"schechtel\")\n",
    "        \n",
    "    for i in classes:\n",
    "        files = hdfs.get_file_info(fs.FileSelector(f'/project/schechtel/animals/{i}')) # Pro Verzechniss werden alle Pfade aufgelistet. \n",
    "        print(f\"Class: {i} \\t items: {len(files)}\")\n",
    "        for path in files:\n",
    "            data.append([path.path, i])  # Data: [...PNG , Klasse Dog]\n",
    "            \n",
    "    np.random.shuffle(data) # Shuffle\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96dc114-b1f6-4f60-acf2-9c6ecf134811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "# Dataset\n",
    "class create_trainset(Dataset):\n",
    "    def __init__(self, data_paths):  \n",
    "        \"\"\"\n",
    "        data_paths: Die Pfade die mit get_filenames ermittelt wurde.\n",
    "        - Könnte auch hier gemacht werden... \n",
    "        \"\"\"\n",
    "        self.data_paths = data_paths  # Data: [...PNG , Klasse Dog]\n",
    "        self.hdfs = fs.HadoopFileSystem(\"hdfs://sun.bigdata.fh-aachen.de\", port=9000, user=\"schechtel\")  # HDFS  Verbindung \n",
    "        # Sonstige Angaben... \n",
    "        self.img_dim    = (32, 32) # 227\n",
    "        self.transform = transforms.Compose(\n",
    "                           [transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] )\n",
    "        self.class_map = {'dog':0, 'chicken': 1}\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)  # Länge des Datasets \n",
    "\n",
    "    def __getitem__(self, idx):      # Iteriere mit idx:   __getitem__(idx)\n",
    "         \n",
    "        img_path, class_name = self.data_paths[idx]    # img_path=...PNG,  class_name=... dog\n",
    "\n",
    "        loded_image = skimage.io.imread( self.hdfs.open_input_file(img_path) )\n",
    "        img = Image.fromarray(np.uint8(loded_image)) \n",
    "        img = fn.center_crop(img, self.img_dim) \n",
    "        img = self.transform(img) \n",
    "        \n",
    "        class_id = self.class_map[class_name]   # dog => 0\n",
    "        \n",
    "        img_tensor = torch.from_numpy(np.asarray(img).copy())\n",
    "        \n",
    "        class_id = torch.tensor([class_id]) \n",
    "\n",
    "        return img_tensor, class_id \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e8bc6-3bdf-4f2b-93e4-cc7e2501ca15",
   "metadata": {},
   "source": [
    "Wenn die Daten lokal auf dem Rechner sind, könnte das Laden der Daten so aussehen wie unten. <br>\n",
    "Im Dataset ermitteln wir mittels Python alle Bildnamen und Pfade.\n",
    "\n",
    "Im Dataset können auch Subsets von Pfaden für veschiedene Worker erstellt werden, oder auch Datasets für das Testen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9360ce-e003-4a36-bac3-5914b8b96b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mask_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.classes=['with_mask','without_mask']             # 2 Klassen\n",
    "        self.class_map={'with_mask':0, 'without_mask':1 }\n",
    "        self.dir=\"01work/Datasets/facemask/archive/\"          # ../archive/with_mask  |  ../archive/without_mask  \n",
    "        self.img_paths=[]\n",
    "        \n",
    "        for klass in self.classes:\n",
    "            tmp_list = os.listdir(f\"{self.dir}{klass}\")   # os.listdir(): Liste Verzeichniss auf und gebe als Liste zurück \n",
    "            print(f\"Klasse: {klass}, Items: {len(tmp_list)}\")\n",
    "            for path in tmp_list:\n",
    "                self.img_paths.append([f\"{self.dir}{klass}/{path}\", self.class_map[klass]]) #   [....PNG , with_mask => 0 ]\n",
    "        print(f\"Gesamte Items: {len(self.img_paths)}\")    \n",
    "        \n",
    "        # Shuffle...\n",
    "        # worker n soll diese Pfade Pfade bekommen... \n",
    "        # Testimg = ...\n",
    "                \n",
    "    def __len__(self):\n",
    "          return len( self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = skimage.io.imread( self.img_paths[idx][0] )\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img_tensor = torch.from_numpy(np.asarray(img).copy())\n",
    "        \n",
    "        return img_tensor, torch.tensor(int(self.img_paths[idx][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c657d4-269a-436d-902c-8ea468246898",
   "metadata": {},
   "source": [
    "# 5. Model Speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08652d-b950-4ab5-be06-cb7f06236502",
   "metadata": {},
   "source": [
    "Bei dem momentanen Stand wird das Model lokal gespeichert, ohne die Modelle selber mit dem Client zu teilen. \n",
    "\n",
    "Wenn das Model geladen werden soll, werden die einzelnen Teilmodelle im RPC-Kontext geladen und stehen zur Verfügung. \n",
    "\n",
    "Wie das Speichern und Laden realisiert wird, kann vom Anwender programmiert werden. Standardmäßig wird das Model lokal als Dict gespeichert. \n",
    "\n",
    "<br>\n",
    "\n",
    "SAVING AND LOADING MODELS: https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-and-loading-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04708da5-eee7-4aa8-9bc2-bd94bdb0062c",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/ptmp_rpc6.PNG\" width=\"865px;\" hight=\"665px;\" >"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c17ef7e-4f52-48b3-b814-afccf13b10c3",
   "metadata": {},
   "source": [
    "# - AlexNet - #\n",
    "def loadModelShardsLokalOnWorker(self, path:str=\"./\"): # Speichere beteiligte Netze. \n",
    "    self.part1.load_local(path)\n",
    "        \n",
    "    self.part2.remote().load_local(path)\n",
    "    self.part3.remote().load_local(path)\n",
    "    \n",
    "# - Im Teilnetz - #  \n",
    "# Hier kann eine andere Art des speicherns programmiert werden. \n",
    "def save_local(self, path=\"./\"):\n",
    "    print(f\"net3 save: {str(path+self.savename+'.pt')}\")\n",
    "    torch.save(self.state_dict(), str(path+self.savename+\".pt\") )\n",
    "    \n",
    "def load_local(self, path=\"./\"):\n",
    "    print(f\"net3 load from {str(path+self.savename+'.pt')}\")\n",
    "    self.load_state_dict(torch.load(str(path+self.savename+\".pt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48bcc4-ac00-4200-98c9-09a801077463",
   "metadata": {},
   "source": [
    "# 6. Model Laden und Evaluieren (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe9dd6-4443-42c1-a2ad-0d2caea29ec1",
   "metadata": {},
   "source": [
    "Um das Model wieder zu laden und zu Nutzen, muss eine Funktion verwendet werden, die im RPC-Kontext läuft. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f6d0aedf-16ae-4f8a-ac2b-8b77f76da0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lade Datei hoch\n",
    "client.upload_file('pytorch_AlexNetMP.py')\n",
    "import pytorch_AlexNetMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3c717008-6a9e-4f1e-a605-cb4955eb36ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Funktion im RPC-Kontext ##\n",
    "\n",
    "def eval_func():\n",
    "    pub_stats  = Pub(\"my_channel\")            # Channel          \n",
    "    device = torch.device(\"cuda\")  # 'cuda': Nutze alle GPUs | 0: nutze GPU 0 | 'cpu': Nutze CPU, Backend auf gloo stellen | \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "   \n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465],\n",
    "            std=[0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "    \n",
    "    # Cifar10 Testset\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    # Dataloader                                     \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model = pytorch_AlexNetMP.AlexNet().to(device) # Erstelle AlexNet Model aus Teilnetzen. \n",
    "    model.loadModelShardsLokalOnWorker()           # Die Teilnetze sollen das gespeicherte Laden.\n",
    "    # Jetzt ist das Netz wieder verfügbar # \n",
    "\n",
    "   \n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "        \n",
    "            images = images.cuda()      # CUDA for GPU usage  \n",
    "            labels = labels.cuda()      # CUDA for GPU usage \n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)  \n",
    "            \n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    msg=f'Accuracy of the network on the 10000 test images: {100 * correct // total} %'\n",
    "\n",
    "    pub_stats.put({'msg': msg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "85a46b9c-abcf-46b4-8641-3003fbbadc05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: 3\n"
     ]
    }
   ],
   "source": [
    "# Dask \n",
    "workers = client.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "print(f\"Worker: {n_workers}\")\n",
    "\n",
    "client.wait_for_workers(n_workers)\n",
    "\n",
    "rh = DaskResultHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e259996f-f74a-4d62-895a-f063cf8a7418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 70 %\n",
      "CPU times: user 32.3 ms, sys: 4.8 ms, total: 37.1 ms\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "futures = run(client, eval_func)\n",
    "%time rh.process_results(futures, raise_errors=False)\n",
    "time.sleep(1)\n",
    "del rh, futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5d29a-ae42-4f09-a009-a81fc0234fc4",
   "metadata": {},
   "source": [
    "## 6.2. Weiteres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4e268-1ac2-4fb2-ad74-be8a12b237b2",
   "metadata": {},
   "source": [
    "Die ganze Evaluierung kann in Funktionen ausgelagert und vereinfacht werden.<br>\n",
    "Mit Torchmetric kann die Evaluierung vereinfacht werden und mehr. \n",
    "\n",
    "Um mehr Übersicht zu haben, kann auch das TensorBoard von TensorFlow für PyTorch eingesetzt werden.\n",
    "\n",
    "<br>\n",
    "\n",
    "WELCOME TO TORCHMETRICS: https://torchmetrics.readthedocs.io/en/stable/ <br>\n",
    "TORCHMETRICS Beispiel: https://lightning.ai/docs/pytorch/stable/ecosystem/metrics.html <br>\n",
    "TORCH.UTILS.TENSORBOARD: https://pytorch.org/docs/stable/tensorboard.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8d23f86a-2752-4d09-a8fd-745ae6681583",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torchmetrics) (1.23.5)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torchmetrics) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/rapids/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.6.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.14.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.101)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (10.9.0.58)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/rapids/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (0.40.0)\n",
      "Requirement already satisfied: lit in /opt/conda/envs/rapids/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/envs/rapids/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.26.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/rapids/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics  # Muss überall installiert sein "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d967851c-9583-416f-931c-61f8bcb1bce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "def eval_func():\n",
    "    pub_stats  = Pub(\"my_channel\")            # Channel          \n",
    "    device = torch.device(\"cuda\")  # 'cuda': Nutze alle GPUs | 0: nutze GPU 0 | 'cpu': Nutze CPU, Backend auf gloo stellen | \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "   \n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465],\n",
    "            std=[0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)                                   \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False)\n",
    "\n",
    "    model = pytorch_AlexNetMP.AlexNet().to(device) \n",
    "    model.loadModelShardsLokalOnWorker()           \n",
    "   \n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "        \n",
    "            images = images.cuda()      # CUDA for GPU usage  \n",
    "            labels = labels.cuda()      # CUDA for GPU usage \n",
    "            outputs = model(images) \n",
    "            \n",
    "            acc = metric(outputs, labels)\n",
    "         \n",
    "    acc = metric.compute()        \n",
    "    msg=acc\n",
    "    pub_stats.put({'msg': msg})\n",
    "    metric.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0db348-4ffb-42b0-9561-804a837d94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
